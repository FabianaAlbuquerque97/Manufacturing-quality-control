{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Controle de Qualidade de Fabricação** ☑\n",
        "Inspeção visual de produtos na fábrica.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Visão geral:**\n",
        "\n",
        "Esta competição consiste na análise de imagens de garrafas fabricadas por uma indústria específica de refrigerantes.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Disciplina: Redes Neurais e Aprendizado Profundo**\n",
        "\n",
        "Aluna: Fabiana de Albuquerque.\n",
        "\n",
        "Este notebook aplica redes neurais convolucionais para detectar defeitos em garrafas de refrigerante, com base em inspeção visual automática. O projeto envolve:\n",
        "\n",
        "Classificação Multilabel com CNN (TensorFlow)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "✅ Etapas do notebook:\n",
        "\n",
        "##### 1. Análise exploratória dos dados\n",
        "##### 2. Pré-processamento das imagens\n",
        "##### 3. Construção e treinamento do modelo\n",
        "##### 4. Avaliação com gráficos\n",
        "##### 5. Geração do arquivo de submissão\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cqm7uA5ofkPE",
        "outputId": "aeebe82d-8823-4361-875f-7202ea07a47f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in c:\\users\\fabia\\anaconda3\\lib\\site-packages (4.11.0.86)\n",
            "Requirement already satisfied: pandas in c:\\users\\fabia\\anaconda3\\lib\\site-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\fabia\\anaconda3\\lib\\site-packages (3.9.2)\n",
            "Requirement already satisfied: seaborn in c:\\users\\fabia\\anaconda3\\lib\\site-packages (0.13.2)\n",
            "Requirement already satisfied: gradio in c:\\users\\fabia\\anaconda3\\lib\\site-packages (5.30.0)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\fabia\\anaconda3\\lib\\site-packages (1.5.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from gradio) (4.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.10.1 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from gradio) (1.10.1)\n",
            "Requirement already satisfied: groovy~=0.1 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from gradio) (0.27.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from gradio) (0.31.4)\n",
            "Requirement already satisfied: jinja2<4.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from gradio) (2.1.3)\n",
            "Requirement already satisfied: orjson~=3.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from gradio) (2.8.2)\n",
            "Requirement already satisfied: pydub in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: ruff>=0.9.3 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from gradio) (0.11.10)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from gradio) (0.15.4)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from gradio) (4.13.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from gradio) (0.34.2)\n",
            "Requirement already satisfied: fsspec in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from gradio-client==1.10.1->gradio) (2024.6.1)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.6.0)\n",
            "Collecting pydantic-core==2.20.1 (from pydantic<2.12,>=2.0->gradio)\n",
            "  Using cached pydantic_core-2.20.1-cp312-none-win_amd64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: click<8.2,>=8.0.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.0)\n",
            "Requirement already satisfied: rich>=10.11.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from click<8.2,>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (3.13.1)\n",
            "Requirement already satisfied: requests in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (4.66.5)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.15.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.2.3)\n",
            "Using cached pydantic_core-2.20.1-cp312-none-win_amd64.whl (1.9 MB)\n",
            "Installing collected packages: pydantic-core\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.33.2\n",
            "    Uninstalling pydantic_core-2.33.2:\n",
            "      Successfully uninstalled pydantic_core-2.33.2\n",
            "Successfully installed pydantic-core-2.20.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\fabia\\anaconda3\\Lib\\site-packages\\~-dantic_core'.\n",
            "  You can safely remove it manually.\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python pandas matplotlib seaborn gradio scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting albumentations\n",
            "  Using cached albumentations-2.0.8-py3-none-any.whl.metadata (43 kB)\n",
            "Requirement already satisfied: scikit-image in c:\\users\\fabia\\anaconda3\\lib\\site-packages (0.24.0)\n",
            "Requirement already satisfied: numpy>=1.24.4 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from albumentations) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.10.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from albumentations) (1.13.1)\n",
            "Requirement already satisfied: PyYAML in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from albumentations) (6.0.1)\n",
            "Collecting pydantic>=2.9.2 (from albumentations)\n",
            "  Using cached pydantic-2.11.5-py3-none-any.whl.metadata (67 kB)\n",
            "Collecting albucore==0.0.24 (from albumentations)\n",
            "  Using cached albucore-0.0.24-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting opencv-python-headless>=4.9.0.80 (from albumentations)\n",
            "  Using cached opencv_python_headless-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from albucore==0.0.24->albumentations) (3.12.5)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from albucore==0.0.24->albumentations) (6.2.1)\n",
            "Requirement already satisfied: networkx>=2.8 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from scikit-image) (3.3)\n",
            "Requirement already satisfied: pillow>=9.1 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from scikit-image) (10.4.0)\n",
            "Requirement already satisfied: imageio>=2.33 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from scikit-image) (2.33.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from scikit-image) (2023.4.12)\n",
            "Requirement already satisfied: packaging>=21 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from scikit-image) (24.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from pydantic>=2.9.2->albumentations) (0.6.0)\n",
            "Collecting pydantic-core==2.33.2 (from pydantic>=2.9.2->albumentations)\n",
            "  Using cached pydantic_core-2.33.2-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from pydantic>=2.9.2->albumentations) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from pydantic>=2.9.2->albumentations) (0.4.1)\n",
            "Using cached albumentations-2.0.8-py3-none-any.whl (369 kB)\n",
            "Using cached albucore-0.0.24-py3-none-any.whl (15 kB)\n",
            "Using cached opencv_python_headless-4.11.0.86-cp37-abi3-win_amd64.whl (39.4 MB)\n",
            "Using cached pydantic-2.11.5-py3-none-any.whl (444 kB)\n",
            "Using cached pydantic_core-2.33.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
            "Installing collected packages: pydantic-core, opencv-python-headless, pydantic, albucore, albumentations\n",
            "\n",
            "  Attempting uninstall: pydantic-core\n",
            "\n",
            "    Found existing installation: pydantic_core 2.20.1\n",
            "\n",
            "    Uninstalling pydantic_core-2.20.1:\n",
            "\n",
            "      Successfully uninstalled pydantic_core-2.20.1\n",
            "\n",
            "   -------- ------------------------------- 1/5 [opencv-python-headless]\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not install packages due to an OSError: [WinError 5] Acesso negado: 'c:\\\\Users\\\\fabia\\\\anaconda3\\\\Lib\\\\site-packages\\\\cv2\\\\cv2.pyd'\n",
            "Consider using the `--user` option or check the permissions.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install albumentations scikit-image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJWgT2Zyl3HE",
        "outputId": "32de5563-5441-4fd6-8b1d-1414c3780541"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in c:\\users\\fabia\\anaconda3\\lib\\site-packages (1.5.1)\n",
            "Requirement already satisfied: imbalanced-learn in c:\\users\\fabia\\anaconda3\\lib\\site-packages (0.12.3)\n",
            "Requirement already satisfied: pandas in c:\\users\\fabia\\anaconda3\\lib\\site-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in c:\\users\\fabia\\anaconda3\\lib\\site-packages (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn imbalanced-learn pandas numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pynvml in c:\\users\\fabia\\anaconda3\\lib\\site-packages (12.0.0)\n",
            "Requirement already satisfied: nvidia-ml-py<13.0.0a0,>=12.0.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from pynvml) (12.575.51)\n"
          ]
        }
      ],
      "source": [
        "!pip install pynvml "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in c:\\users\\fabia\\anaconda3\\lib\\site-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from tensorflow) (2.2.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from tensorflow) (4.25.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from tensorflow) (3.9.2)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.7.1)\n",
            "Requirement already satisfied: namex in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\fabia\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "mhT98HJPYyw3"
      },
      "outputs": [],
      "source": [
        "# # Inspeção de Garrafas com Deep Learning\n",
        "#\n",
        "# **Objetivo:** Detectar 8 tipos de defeitos em garrafas usando visão computacional\n",
        "#\n",
        "# **Funcionalidades adicionadas:**\n",
        "# 1. Gráficos detalhados das métricas de treinamento\n",
        "# 2. Interface interativa com Gradio para testar imagens\n",
        "\n",
        "\n",
        "# ============================\n",
        "# 1. IMPORTAÇÃO DE BIBLIOTECAS\n",
        "# ============================\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import applications\n",
        "from sklearn.impute import SimpleImputer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import gradio as gr\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "import os\n",
        "os.environ['TF_GPU_THREAD_MODE'] = 'gpu_private'\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from tensorflow.keras.applications import ResNet50, InceptionV3\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "import gc\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import shutil\n",
        "from collections import Counter\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
        "from sklearn.metrics import accuracy_score, f1_score \n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diretório de dados existe? True\n",
            "Diretório de treino existe? True\n",
            "Diretório de teste existe? True\n"
          ]
        }
      ],
      "source": [
        "# SOLUÇÃO PARA O ERRO: Usar raw string com r''\n",
        "DATA_DIR = r'C:\\Users\\fabia\\Downloads\\manufacturing-quality-control'  # Raw string\n",
        "TRAIN_DIR = os.path.join(DATA_DIR, 'train')\n",
        "TEST_DIR = os.path.join(DATA_DIR, 'test')\n",
        "\n",
        "# Verificar se diretórios existem\n",
        "print(f\"Diretório de dados existe? {os.path.exists(DATA_DIR)}\")\n",
        "print(f\"Diretório de treino existe? {os.path.exists(TRAIN_DIR)}\")\n",
        "print(f\"Diretório de teste existe? {os.path.exists(TEST_DIR)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        },
        "id": "xxcPZ0SpYyqf",
        "outputId": "73aa995a-c738-4495-9fb8-571e381369cc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\fabia\\AppData\\Local\\Temp\\ipykernel_6540\\4195032435.py:21: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ============================\n",
        "# 2. ANÁLISE EXPLORATÓRIA\n",
        "# ============================\n",
        "\n",
        "# Carregar arquivos CSV\n",
        "train_df = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'))\n",
        "test_df = pd.read_csv(os.path.join(DATA_DIR, 'test.csv'))\n",
        "\n",
        "# Definir colunas de defeitos\n",
        "defect_columns = [\n",
        "    'CONTENT_HIGH', 'CONTENT_LOW', 'COVER_NONE', 'BOTTLE_SMASHED',\n",
        "    'LABEL_WHITE', 'LABEL_MISPLACED', 'LABEL_NONE', 'BOTTLE_NONE'\n",
        "]\n",
        "\n",
        "# Preencher valores NaN com 0 e converter para int\n",
        "train_df[defect_columns] = train_df[defect_columns].fillna(0).astype(int)\n",
        "test_df[defect_columns] = test_df[defect_columns].fillna(0).astype(int)\n",
        "\n",
        "# Plotar distribuição de defeitos\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(\n",
        "    x=defect_columns,\n",
        "    y=train_df[defect_columns].sum().values,\n",
        "    palette=\"viridis\"\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train DataFrame:\n",
            "            id  CONTENT_HIGH  CONTENT_LOW  COVER_NONE  BOTTLE_SMASHED  \\\n",
            "0  train_1.jpg             0            0           0               0   \n",
            "1  train_2.jpg             0            0           0               0   \n",
            "2  train_3.jpg             1            0           1               0   \n",
            "3  train_4.jpg             1            0           1               0   \n",
            "4  train_5.jpg             1            0           1               0   \n",
            "\n",
            "   LABEL_WHITE  LABEL_MISPLACED  LABEL_NONE  BOTTLE_NONE  \n",
            "0            0                0           0            0  \n",
            "1            0                0           0            0  \n",
            "2            0                1           0            0  \n",
            "3            0                0           0            0  \n",
            "4            0                0           0            0  \n",
            "\n",
            "Test DataFrame:\n",
            "           id  CONTENT_HIGH  CONTENT_LOW  COVER_NONE  BOTTLE_SMASHED  \\\n",
            "0  test_1.jpg             0            0           0               0   \n",
            "1  test_2.jpg             0            0           0               0   \n",
            "2  test_3.jpg             0            0           0               0   \n",
            "3  test_4.jpg             0            0           0               0   \n",
            "4  test_5.jpg             0            0           0               0   \n",
            "\n",
            "   LABEL_WHITE  LABEL_MISPLACED  LABEL_NONE  BOTTLE_NONE  \n",
            "0            0                0           0            0  \n",
            "1            0                0           0            0  \n",
            "2            0                0           0            0  \n",
            "3            0                0           0            0  \n",
            "4            0                0           0            0  \n"
          ]
        }
      ],
      "source": [
        "# Mostrar primeiras linhas\n",
        "print(\"\\nTrain DataFrame:\")\n",
        "print(train_df.head())\n",
        "print(\"\\nTest DataFrame:\")\n",
        "print(test_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97jTSoahYylK",
        "outputId": "1873f682-64c2-4314-d997-607bc3f709ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "VERIFICAÇÃO E PREPARAÇÃO DO DIRETÓRIO GAN\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "CARREGAMENTO DE IMAGENS REAIS\n",
            "==================================================\n",
            "Imagens reais carregadas: 77\n",
            "Imagens ignoradas: 0\n",
            "\n",
            "==================================================\n",
            "CARREGANDO IMAGENS GAN EXISTENTES\n",
            "==================================================\n",
            "Imagens GAN carregadas: 50\n",
            "\n",
            "==================================================\n",
            "BALANCEAMENTO DE CLASSES PARA PERFORMANCE ÓTIMA\n",
            "==================================================\n",
            "\n",
            "Distribuição inicial de classes:\n",
            "CONTENT_HIGH: 23 amostras\n",
            "CONTENT_LOW: 8 amostras\n",
            "COVER_NONE: 9 amostras\n",
            "BOTTLE_SMASHED: 7 amostras\n",
            "LABEL_WHITE: 7 amostras\n",
            "LABEL_MISPLACED: 8 amostras\n",
            "LABEL_NONE: 6 amostras\n",
            "BOTTLE_NONE: 6 amostras\n",
            "\n",
            "Classe: CONTENT_HIGH\n",
            "- Amostras atuais: 23\n",
            "- Amostras necessárias: 127\n",
            "- Geradas 127 amostras sintéticas de alta qualidade via Mixup\n",
            "\n",
            "Classe: CONTENT_LOW\n",
            "- Amostras atuais: 8\n",
            "- Amostras necessárias: 142\n",
            "- Geradas 142 amostras sintéticas de alta qualidade via Mixup\n",
            "\n",
            "Classe: COVER_NONE\n",
            "- Amostras atuais: 9\n",
            "- Amostras necessárias: 141\n",
            "- Geradas 141 amostras sintéticas de alta qualidade via Mixup\n",
            "\n",
            "Classe: BOTTLE_SMASHED\n",
            "- Amostras atuais: 7\n",
            "- Amostras necessárias: 143\n",
            "- Geradas 143 amostras sintéticas de alta qualidade via Mixup\n",
            "\n",
            "Classe: LABEL_WHITE\n",
            "- Amostras atuais: 7\n",
            "- Amostras necessárias: 143\n",
            "- Geradas 143 amostras sintéticas de alta qualidade via Mixup\n",
            "\n",
            "Classe: LABEL_MISPLACED\n",
            "- Amostras atuais: 8\n",
            "- Amostras necessárias: 142\n",
            "- Geradas 142 amostras sintéticas de alta qualidade via Mixup\n",
            "\n",
            "Classe: LABEL_NONE\n",
            "- Amostras atuais: 6\n",
            "- Amostras necessárias: 144\n",
            "- Geradas 144 amostras sintéticas de alta qualidade via Mixup\n",
            "\n",
            "Classe: BOTTLE_NONE\n",
            "- Amostras atuais: 6\n",
            "- Amostras necessárias: 144\n",
            "- Geradas 144 amostras sintéticas de alta qualidade via Mixup\n",
            "\n",
            "Distribuição final de classes:\n",
            "CONTENT_HIGH: 537.6072951432402 amostras\n",
            "CONTENT_LOW: 194.16118889946685 amostras\n",
            "COVER_NONE: 291.2960032781896 amostras\n",
            "BOTTLE_SMASHED: 180.24361065275338 amostras\n",
            "LABEL_WHITE: 179.77208392985926 amostras\n",
            "LABEL_MISPLACED: 208.67026181567132 amostras\n",
            "LABEL_NONE: 164.14567626012084 amostras\n",
            "BOTTLE_NONE: 156.2361087190376 amostras\n",
            "\n",
            "==================================================\n",
            "CONSTRUÇÃO DO MODELO PARA ALTA ACURÁCIA\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "VALIDAÇÃO CRUZADA PARA GENERALIZAÇÃO\n",
            "==================================================\n",
            "\n",
            "Treinando fold #1\n",
            "\n",
            "Treinando fold #1\n",
            "\n",
            "Treinando fold #1\n",
            "\n",
            "Treinando fold #1\n",
            "\n",
            "Treinando fold #1\n"
          ]
        }
      ],
      "source": [
        "# ============================\n",
        "# PRÉ-PROCESSAMENTO \n",
        "# ============================\n",
        "\n",
        "# Configurações\n",
        "BASE_DIR = os.path.join(os.path.expanduser('~'), 'Downloads', 'manufacturing-quality-control')\n",
        "GAN_DIR = os.path.join(BASE_DIR, 'gan_generated')\n",
        "TARGET_SAMPLES = 150  # Aumentado para melhor performance\n",
        "\n",
        "# 1. Criação automática do diretório GAN e geração de fallback REALISTA\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"VERIFICAÇÃO E PREPARAÇÃO DO DIRETÓRIO GAN\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "if not os.path.exists(GAN_DIR):\n",
        "    os.makedirs(GAN_DIR)\n",
        "    print(f\"Diretório GAN criado em: {GAN_DIR}\")\n",
        "\n",
        "gan_images = [f for f in os.listdir(GAN_DIR) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "# Função para gerar imagens mais realistas\n",
        "def generate_realistic_fallback(real_images, num_images=50):\n",
        "    \"\"\"Gera imagens de fallback baseadas em características de imagens reais\"\"\"\n",
        "    generated = []\n",
        "    for _ in range(num_images):\n",
        "        # Selecionar uma imagem real aleatória como base\n",
        "        base_img = real_images[np.random.randint(0, len(real_images))]\n",
        "        \n",
        "        # Aplicar transformações realistas\n",
        "        transformed = base_img.copy()\n",
        "        \n",
        "        # Adicionar variações de cor\n",
        "        color_shift = np.random.uniform(0.9, 1.1, 3)\n",
        "        for c in range(3):\n",
        "            transformed[..., c] = np.clip(transformed[..., c] * color_shift[c], 0, 1)\n",
        "        \n",
        "        # Adicionar ruído gaussiano suave\n",
        "        noise = np.random.normal(0, 0.02, transformed.shape)\n",
        "        transformed = np.clip(transformed + noise, 0, 1)\n",
        "        \n",
        "        # Adicionar pequenas deformações\n",
        "        if np.random.rand() > 0.5:\n",
        "            transformed = cv2.resize(transformed, (230, 230))\n",
        "            transformed = transformed[3:227, 3:227]\n",
        "        \n",
        "        generated.append(transformed)\n",
        "    return generated\n",
        "\n",
        "# 2. Carregamento de imagens reais PRIMEIRO (para gerar fallback realista)\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"CARREGAMENTO DE IMAGENS REAIS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "def load_and_preprocess(image_path, target_size=(224, 224)):\n",
        "    \"\"\"Carrega e pré-processa imagem mantendo cores\"\"\"\n",
        "    try:\n",
        "        img = cv2.imread(image_path)\n",
        "        if img is None:\n",
        "            raise ValueError(f\"Arquivo não pode ser lido: {image_path}\")\n",
        "        \n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img, target_size)\n",
        "        return img / 255.0\n",
        "    except Exception as e:\n",
        "        print(f\"Erro no processamento: {e}\")\n",
        "        return None\n",
        "\n",
        "X_real = []\n",
        "y_real = []\n",
        "train_dir = os.path.join(BASE_DIR, 'train')\n",
        "skipped = 0\n",
        "\n",
        "for idx, row in train_df.iterrows():\n",
        "    found = False\n",
        "    for ext in ['', '.jpg', '.jpeg', '.png']:\n",
        "        img_path = os.path.join(train_dir, f\"{row['id']}{ext}\")\n",
        "        if os.path.exists(img_path):\n",
        "            img = load_and_preprocess(img_path)\n",
        "            if img is not None:\n",
        "                X_real.append(img)\n",
        "                y_real.append(row[defect_columns].values.astype(int))\n",
        "                found = True\n",
        "                break\n",
        "    \n",
        "    if not found:\n",
        "        skipped += 1\n",
        "        print(f\"ATENÇÃO: Imagem real não encontrada: {row['id']}\")\n",
        "\n",
        "print(f\"Imagens reais carregadas: {len(X_real)}\")\n",
        "print(f\"Imagens ignoradas: {skipped}\")\n",
        "\n",
        "# 3. Geração de fallback realista se necessário\n",
        "if len(gan_images) == 0 and len(X_real) > 0:\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"GERANDO IMAGENS DE FALLBACK REALISTAS\")\n",
        "    print(\"=\"*50)\n",
        "    \n",
        "    X_gan = generate_realistic_fallback(X_real, num_images=50)\n",
        "    \n",
        "    # Salvar imagens geradas\n",
        "    for i, img in enumerate(X_gan):\n",
        "        img_path = os.path.join(GAN_DIR, f\"realistic_fallback_{i}.jpg\")\n",
        "        img_uint8 = (img * 255).astype(np.uint8)\n",
        "        cv2.imwrite(img_path, cv2.cvtColor(img_uint8, cv2.COLOR_RGB2BGR))\n",
        "    \n",
        "    print(f\"Geradas e salvas {len(X_gan)} imagens de fallback realistas\")\n",
        "    gan_images = [f for f in os.listdir(GAN_DIR) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "else:\n",
        "    # 4. Carregamento de imagens GAN existentes\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"CARREGANDO IMAGENS GAN EXISTENTES\")\n",
        "    print(\"=\"*50)\n",
        "    \n",
        "    X_gan = []\n",
        "    for gan_img in gan_images:\n",
        "        img_path = os.path.join(GAN_DIR, gan_img)\n",
        "        img = load_and_preprocess(img_path)\n",
        "        if img is not None:\n",
        "            X_gan.append(img)\n",
        "\n",
        "print(f\"Imagens GAN carregadas: {len(X_gan)}\")\n",
        "\n",
        "# 5. Balanceamento inteligente com verificação de mínimo\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"BALANCEAMENTO DE CLASSES PARA PERFORMANCE ÓTIMA\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Combinar dados reais e GAN\n",
        "X_combined = np.array(X_real + X_gan)\n",
        "y_combined = np.array(y_real + [np.zeros(len(defect_columns), dtype=int)] * len(X_gan))\n",
        "\n",
        "# Verificar distribuição inicial\n",
        "class_counts = y_combined.sum(axis=0)\n",
        "print(\"\\nDistribuição inicial de classes:\")\n",
        "for i, col in enumerate(defect_columns):\n",
        "    print(f\"{col}: {class_counts[i]} amostras\")\n",
        "\n",
        "# Garantir mínimo de 5 amostras por classe para evitar problemas\n",
        "for i in range(len(defect_columns)):\n",
        "    if class_counts[i] < 5:\n",
        "        num_needed = 5 - class_counts[i]\n",
        "        print(f\"ATENÇÃO: Classe {defect_columns[i]} tem apenas {class_counts[i]} amostra(s). Adicionando {num_needed} amostras extras.\")\n",
        "        \n",
        "        # Criar amostras sintéticas de alta qualidade\n",
        "        new_samples = generate_realistic_fallback(X_combined, num_needed)\n",
        "        new_labels = np.zeros((num_needed, len(defect_columns)))\n",
        "        new_labels[:, i] = 1\n",
        "        \n",
        "        X_combined = np.vstack([X_combined, new_samples])\n",
        "        y_combined = np.vstack([y_combined, new_labels])\n",
        "\n",
        "# Função de Mixup aprimorada para melhor generalização\n",
        "def apply_mixup(X, y, num_samples, alpha=0.7):\n",
        "    \"\"\"Gera amostras sintéticas usando técnica Mixup com controle de qualidade\"\"\"\n",
        "    X_new, y_new = [], []\n",
        "    for _ in range(num_samples):\n",
        "        # Selecionar amostras de classes diferentes para aumentar diversidade\n",
        "        class_idx1, class_idx2 = np.random.choice(len(defect_columns), 2, replace=False)\n",
        "        indices1 = np.where(y[:, class_idx1] == 1)[0]\n",
        "        indices2 = np.where(y[:, class_idx2] == 1)[0]\n",
        "        \n",
        "        if len(indices1) > 0 and len(indices2) > 0:\n",
        "            i = np.random.choice(indices1)\n",
        "            j = np.random.choice(indices2)\n",
        "            lam = np.random.beta(alpha, alpha)\n",
        "            mixed_img = lam * X[i] + (1-lam) * X[j]\n",
        "            mixed_label = lam * y[i] + (1-lam) * y[j]\n",
        "            X_new.append(mixed_img)\n",
        "            y_new.append(mixed_label)\n",
        "    return np.array(X_new), np.array(y_new)\n",
        "\n",
        "# Balanceamento por classe com meta aumentada\n",
        "X_balanced = []\n",
        "y_balanced = []\n",
        "\n",
        "for class_idx, class_name in enumerate(defect_columns):\n",
        "    class_indices = np.where(y_combined[:, class_idx] == 1)[0]\n",
        "    current_count = len(class_indices)\n",
        "    num_needed = max(0, TARGET_SAMPLES - current_count)\n",
        "    \n",
        "    print(f\"\\nClasse: {class_name}\")\n",
        "    print(f\"- Amostras atuais: {current_count}\")\n",
        "    print(f\"- Amostras necessárias: {num_needed}\")\n",
        "    \n",
        "    # Adicionar amostras existentes\n",
        "    if current_count > 0:\n",
        "        X_balanced.extend(X_combined[class_indices])\n",
        "        y_balanced.extend(y_combined[class_indices])\n",
        "    \n",
        "    # Gerar amostras adicionais se necessário\n",
        "    if num_needed > 0:\n",
        "        X_mix, y_mix = apply_mixup(X_combined, y_combined, num_samples=num_needed)\n",
        "        X_balanced.extend(X_mix)\n",
        "        y_balanced.extend(y_mix)\n",
        "        print(f\"- Geradas {num_needed} amostras sintéticas de alta qualidade via Mixup\")\n",
        "\n",
        "# Converter para arrays\n",
        "X_balanced = np.array(X_balanced)\n",
        "y_balanced = np.array(y_balanced)\n",
        "\n",
        "# Verificar distribuição final\n",
        "print(\"\\nDistribuição final de classes:\")\n",
        "final_counts = y_balanced.sum(axis=0)\n",
        "for i, col in enumerate(defect_columns):\n",
        "    print(f\"{col}: {final_counts[i]} amostras\")\n",
        "\n",
        "# 6. CONSTRUÇÃO DO MODELO COM REGULARIZAÇÃO FORTE\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"CONSTRUÇÃO DO MODELO PARA ALTA ACURÁCIA\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "def create_regularized_model(input_shape=(224, 224, 3), num_classes=8):\n",
        "    \"\"\"Cria modelo com regularização pesada para evitar overfitting\"\"\"\n",
        "    # Camada de entrada\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "    \n",
        "    # Pré-processamento\n",
        "    x = tf.keras.applications.efficientnet.preprocess_input(inputs)\n",
        "    \n",
        "    # Base do modelo com pesos ImageNet\n",
        "    base_model = EfficientNetB0(\n",
        "        include_top=False,\n",
        "        weights='imagenet',\n",
        "        input_shape=input_shape,\n",
        "        pooling='avg'\n",
        "    )\n",
        "    \n",
        "    # Congelar camadas iniciais, descongelar camadas finais\n",
        "    for layer in base_model.layers[:150]:\n",
        "        layer.trainable = False\n",
        "    for layer in base_model.layers[150:]:\n",
        "        layer.trainable = True\n",
        "    \n",
        "    # Adicionar regularização pesada\n",
        "    x = base_model(x)\n",
        "    x = layers.Dense(256, activation='relu', \n",
        "                    kernel_regularizer=regularizers.l2(0.01),\n",
        "                    activity_regularizer=regularizers.l1(0.005))(x)\n",
        "    x = layers.Dropout(0.6)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    \n",
        "    # Camada de saída\n",
        "    outputs = layers.Dense(num_classes, activation='sigmoid')(x)\n",
        "    \n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "    \n",
        "    # Compilar com métricas otimizadas\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[\n",
        "            'accuracy',\n",
        "            tf.keras.metrics.Precision(name='precision'),\n",
        "            tf.keras.metrics.Recall(name='recall'),\n",
        "            tf.keras.metrics.AUC(name='auc')\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    return model\n",
        "\n",
        "# 7. VALIDAÇÃO CRUZADA PARA GARANTIR ROBUSTEZ\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"VALIDAÇÃO CRUZADA PARA GENERALIZAÇÃO\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Preparar dados para validação cruzada\n",
        "X_data = X_balanced\n",
        "y_data = y_balanced\n",
        "\n",
        "# Configurar K-Fold (5 folds)\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "fold_no = 1\n",
        "histories = []\n",
        "\n",
        "# Converter para problema de classificação única para estratificação\n",
        "y_strat = np.argmax(y_data, axis=1)\n",
        "\n",
        "for train_idx, val_idx in kfold.split(X_data, y_strat):\n",
        "    print(f\"\\nTreinando fold #{fold_no}\")\n",
        "    \n",
        "    # Criar novo modelo para cada fold\n",
        "    model = create_regularized_model()\n",
        "    \n",
        "    # Callbacks para treino\n",
        "    callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=8,\n",
        "            restore_best_weights=True\n",
        "        ),\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=0.5,\n",
        "            patience=3,\n",
        "            min_lr=1e-7\n",
        "        )\n",
        "    ]\n",
        "    \n",
        "    # Data augmentation em tempo real\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rotation_range=45,\n",
        "        width_shift_range=0.25,\n",
        "        height_shift_range=0.25,\n",
        "        shear_range=0.25,\n",
        "        zoom_range=0.25,\n",
        "        brightness_range=[0.7, 1.3],\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "        fill_mode='reflect'\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Precisão mista ativada.\n",
            "\n",
            "============================================================\n",
            " SISTEMA AVANÇADO DE ENSEMBLE PARA CONTROLE DE QUALIDADE\n",
            " CLASSIFICANDO 8 TIPOS DE DEFEITOS\n",
            " META: 90%+ DE ACURÁCIA\n",
            "============================================================\n",
            "[INFO] Distribuição original de defeitos:\n",
            "CONTENT_HIGH       23.0\n",
            "CONTENT_LOW         8.0\n",
            "COVER_NONE          9.0\n",
            "BOTTLE_SMASHED      7.0\n",
            "LABEL_WHITE         7.0\n",
            "LABEL_MISPLACED     8.0\n",
            "LABEL_NONE          6.0\n",
            "BOTTLE_NONE         6.0\n",
            "dtype: float64\n",
            "[INFO] Total de imagens encontradas: 77\n",
            "[INFO] Total de imagens com metadados: 77\n",
            "\n",
            "[INFO] Pesos de classe para balanceamento:\n",
            "  - CONTENT_HIGH: 0.42 (amostras: 23)\n",
            "  - CONTENT_LOW: 1.20 (amostras: 8)\n",
            "  - COVER_NONE: 1.07 (amostras: 9)\n",
            "  - BOTTLE_SMASHED: 1.38 (amostras: 7)\n",
            "  - LABEL_WHITE: 1.38 (amostras: 7)\n",
            "  - LABEL_MISPLACED: 1.20 (amostras: 8)\n",
            "  - LABEL_NONE: 1.60 (amostras: 6)\n",
            "  - BOTTLE_NONE: 1.60 (amostras: 6)\n",
            "[INFO] Total de amostras após balanceamento: 400\n",
            "\n",
            "[INFO] Carregando imagens em memória...\n",
            "[INFO] Dataset balanceado - Imagens: (400, 512, 512, 3), Labels: (400, 8)\n",
            "\n",
            "[INFO] Treinando modelos base para ensemble...\n",
            "\n",
            "============================================================\n",
            " TREINANDO MODELO: EFFICIENTNET \n",
            "============================================================\n",
            "\n",
            "[FASE 1] Treinando cabeça classificadora (efficientnet)\n",
            "Epoch 1/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563ms/step - acc: 0.5033 - auc: 0.5088 - loss: 7.9815\n",
            "Epoch 1: val_auc improved from -inf to 0.52561, saving model to best_efficientnet.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 809ms/step - acc: 0.5034 - auc: 0.5085 - loss: 7.9777 - val_acc: 0.4484 - val_auc: 0.5256 - val_loss: 7.4607 - learning_rate: 1.0000e-04\n",
            "Epoch 2/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574ms/step - acc: 0.5172 - auc: 0.5078 - loss: 7.4556\n",
            "Epoch 2: val_auc did not improve from 0.52561\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 704ms/step - acc: 0.5171 - auc: 0.5073 - loss: 7.4539 - val_acc: 0.3953 - val_auc: 0.5110 - val_loss: 7.0983 - learning_rate: 1.0000e-04\n",
            "Epoch 3/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565ms/step - acc: 0.5037 - auc: 0.4892 - loss: 7.1607\n",
            "Epoch 3: val_auc improved from 0.52561 to 0.53117, saving model to best_efficientnet.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 719ms/step - acc: 0.5040 - auc: 0.4897 - loss: 7.1576 - val_acc: 0.3953 - val_auc: 0.5312 - val_loss: 6.7898 - learning_rate: 1.0000e-04\n",
            "Epoch 4/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517ms/step - acc: 0.5121 - auc: 0.4979 - loss: 6.7982\n",
            "Epoch 4: val_auc improved from 0.53117 to 0.55652, saving model to best_efficientnet.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 661ms/step - acc: 0.5122 - auc: 0.4978 - loss: 6.7965 - val_acc: 0.4766 - val_auc: 0.5565 - val_loss: 6.5171 - learning_rate: 1.0000e-04\n",
            "Epoch 5/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550ms/step - acc: 0.5403 - auc: 0.4914 - loss: 6.5560\n",
            "Epoch 5: val_auc did not improve from 0.55652\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 676ms/step - acc: 0.5400 - auc: 0.4913 - loss: 6.5539 - val_acc: 0.4766 - val_auc: 0.5437 - val_loss: 6.2705 - learning_rate: 1.0000e-04\n",
            "Epoch 6/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557ms/step - acc: 0.5623 - auc: 0.5210 - loss: 6.2919\n",
            "Epoch 6: val_auc did not improve from 0.55652\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 780ms/step - acc: 0.5620 - auc: 0.5207 - loss: 6.2902 - val_acc: 0.4766 - val_auc: 0.5162 - val_loss: 6.0389 - learning_rate: 1.0000e-04\n",
            "Epoch 7/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - acc: 0.5531 - auc: 0.5033 - loss: 6.0325\n",
            "Epoch 7: val_auc improved from 0.55652 to 0.56369, saving model to best_efficientnet.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - acc: 0.5531 - auc: 0.5034 - loss: 6.0311 - val_acc: 0.5703 - val_auc: 0.5637 - val_loss: 5.8185 - learning_rate: 1.0000e-04\n",
            "Epoch 8/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990ms/step - acc: 0.5662 - auc: 0.5073 - loss: 5.8442\n",
            "Epoch 8: val_auc did not improve from 0.56369\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 1s/step - acc: 0.5661 - auc: 0.5072 - loss: 5.8426 - val_acc: 0.5703 - val_auc: 0.5484 - val_loss: 5.6144 - learning_rate: 1.0000e-04\n",
            "Epoch 9/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - acc: 0.5757 - auc: 0.5343 - loss: 5.5897\n",
            "Epoch 9: val_auc did not improve from 0.56369\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 1s/step - acc: 0.5754 - auc: 0.5340 - loss: 5.5889 - val_acc: 0.5703 - val_auc: 0.5551 - val_loss: 5.4139 - learning_rate: 1.0000e-04\n",
            "Epoch 10/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951ms/step - acc: 0.5645 - auc: 0.4785 - loss: 5.4334\n",
            "Epoch 10: val_auc improved from 0.56369 to 0.67881, saving model to best_efficientnet.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 1s/step - acc: 0.5645 - auc: 0.4788 - loss: 5.4318 - val_acc: 0.5703 - val_auc: 0.6788 - val_loss: 5.2284 - learning_rate: 1.0000e-04\n",
            "Epoch 11/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - acc: 0.5640 - auc: 0.4726 - loss: 5.2385\n",
            "Epoch 11: val_auc did not improve from 0.67881\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 1s/step - acc: 0.5643 - auc: 0.4732 - loss: 5.2372 - val_acc: 0.5703 - val_auc: 0.6704 - val_loss: 5.0523 - learning_rate: 1.0000e-04\n",
            "Epoch 12/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550ms/step - acc: 0.5778 - auc: 0.4867 - loss: 5.0028\n",
            "Epoch 12: val_auc did not improve from 0.67881\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 675ms/step - acc: 0.5782 - auc: 0.4873 - loss: 5.0028 - val_acc: 0.5703 - val_auc: 0.6486 - val_loss: 4.8741 - learning_rate: 1.0000e-04\n",
            "Epoch 13/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538ms/step - acc: 0.5957 - auc: 0.5326 - loss: 4.8402\n",
            "Epoch 13: val_auc did not improve from 0.67881\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 667ms/step - acc: 0.5956 - auc: 0.5321 - loss: 4.8399 - val_acc: 0.7078 - val_auc: 0.6544 - val_loss: 4.7051 - learning_rate: 1.0000e-04\n",
            "Epoch 14/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561ms/step - acc: 0.6123 - auc: 0.5178 - loss: 4.6477\n",
            "Epoch 14: val_auc did not improve from 0.67881\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 692ms/step - acc: 0.6120 - auc: 0.5176 - loss: 4.6480 - val_acc: 0.7953 - val_auc: 0.6664 - val_loss: 4.5420 - learning_rate: 1.0000e-04\n",
            "Epoch 15/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563ms/step - acc: 0.6127 - auc: 0.5276 - loss: 4.5060\n",
            "Epoch 15: val_auc improved from 0.67881 to 0.69763, saving model to best_efficientnet.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 714ms/step - acc: 0.6127 - auc: 0.5277 - loss: 4.5057 - val_acc: 0.7953 - val_auc: 0.6976 - val_loss: 4.3926 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 15.\n",
            "\n",
            "[AVISO] Performance insatisfatória na Fase 1 para efficientnet. Pulando fine-tuning.\n",
            "\n",
            "[SUCESSO] Modelo efficientnet treinado e salvo\n",
            "\n",
            "============================================================\n",
            " TREINANDO MODELO: RESNET50 \n",
            "============================================================\n",
            "\n",
            "[FASE 1] Treinando cabeça classificadora (resnet50)\n",
            "Epoch 1/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906ms/step - acc: 0.5142 - auc: 0.5566 - loss: 8.6036\n",
            "Epoch 1: val_auc improved from -inf to 0.63420, saving model to best_resnet50.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - acc: 0.5152 - auc: 0.5582 - loss: 8.5950 - val_acc: 0.3766 - val_auc: 0.6342 - val_loss: 8.3073 - learning_rate: 1.0000e-04\n",
            "Epoch 2/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908ms/step - acc: 0.6134 - auc: 0.7307 - loss: 7.2676\n",
            "Epoch 2: val_auc improved from 0.63420 to 0.75091, saving model to best_resnet50.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 1s/step - acc: 0.6137 - auc: 0.7315 - loss: 7.2612 - val_acc: 0.3766 - val_auc: 0.7509 - val_loss: 7.1935 - learning_rate: 1.0000e-04\n",
            "Epoch 3/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905ms/step - acc: 0.6401 - auc: 0.7864 - loss: 6.2697\n",
            "Epoch 3: val_auc improved from 0.75091 to 0.81896, saving model to best_resnet50.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 1s/step - acc: 0.6405 - auc: 0.7869 - loss: 6.2645 - val_acc: 0.3766 - val_auc: 0.8190 - val_loss: 6.2931 - learning_rate: 1.0000e-04\n",
            "Epoch 4/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905ms/step - acc: 0.6842 - auc: 0.8353 - loss: 5.4840\n",
            "Epoch 4: val_auc improved from 0.81896 to 0.84309, saving model to best_resnet50.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 1s/step - acc: 0.6837 - auc: 0.8350 - loss: 5.4794 - val_acc: 0.4094 - val_auc: 0.8431 - val_loss: 5.4694 - learning_rate: 1.0000e-04\n",
            "Epoch 5/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - acc: 0.7076 - auc: 0.8684 - loss: 4.7693\n",
            "Epoch 5: val_auc improved from 0.84309 to 0.87466, saving model to best_resnet50.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 2s/step - acc: 0.7074 - auc: 0.8682 - loss: 4.7666 - val_acc: 0.4469 - val_auc: 0.8747 - val_loss: 4.8126 - learning_rate: 1.0000e-04\n",
            "Epoch 6/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.7092 - auc: 0.8580 - loss: 4.2522\n",
            "Epoch 6: val_auc improved from 0.87466 to 0.92294, saving model to best_resnet50.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 3s/step - acc: 0.7091 - auc: 0.8583 - loss: 4.2498 - val_acc: 0.4531 - val_auc: 0.9229 - val_loss: 4.2482 - learning_rate: 1.0000e-04\n",
            "Epoch 7/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - acc: 0.7061 - auc: 0.8737 - loss: 3.8548\n",
            "Epoch 7: val_auc improved from 0.92294 to 0.94098, saving model to best_resnet50.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 1s/step - acc: 0.7064 - auc: 0.8741 - loss: 3.8521 - val_acc: 0.5422 - val_auc: 0.9410 - val_loss: 3.7879 - learning_rate: 1.0000e-04\n",
            "Epoch 8/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - acc: 0.7445 - auc: 0.9119 - loss: 3.4727\n",
            "Epoch 8: val_auc improved from 0.94098 to 0.96231, saving model to best_resnet50.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 2s/step - acc: 0.7443 - auc: 0.9117 - loss: 3.4706 - val_acc: 0.6609 - val_auc: 0.9623 - val_loss: 3.4095 - learning_rate: 1.0000e-04\n",
            "Epoch 9/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998ms/step - acc: 0.7331 - auc: 0.8995 - loss: 3.1929\n",
            "Epoch 9: val_auc improved from 0.96231 to 0.97498, saving model to best_resnet50.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 2s/step - acc: 0.7333 - auc: 0.8997 - loss: 3.1912 - val_acc: 0.8031 - val_auc: 0.9750 - val_loss: 3.0967 - learning_rate: 1.0000e-04\n",
            "Epoch 10/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - acc: 0.7472 - auc: 0.8996 - loss: 2.9405\n",
            "Epoch 10: val_auc improved from 0.97498 to 0.98696, saving model to best_resnet50.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 1s/step - acc: 0.7474 - auc: 0.8999 - loss: 2.9392 - val_acc: 0.8734 - val_auc: 0.9870 - val_loss: 2.8400 - learning_rate: 1.0000e-04\n",
            "Epoch 11/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.7611 - auc: 0.9236 - loss: 2.7242\n",
            "Epoch 11: val_auc improved from 0.98696 to 0.98891, saving model to best_resnet50.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 2s/step - acc: 0.7614 - auc: 0.9239 - loss: 2.7230 - val_acc: 0.9016 - val_auc: 0.9889 - val_loss: 2.6232 - learning_rate: 1.0000e-04\n",
            "Epoch 12/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - acc: 0.7734 - auc: 0.9135 - loss: 2.5724\n",
            "Epoch 12: val_auc improved from 0.98891 to 0.99072, saving model to best_resnet50.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 2s/step - acc: 0.7735 - auc: 0.9138 - loss: 2.5712 - val_acc: 0.9047 - val_auc: 0.9907 - val_loss: 2.4515 - learning_rate: 1.0000e-04\n",
            "Epoch 13/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.7600 - auc: 0.9267 - loss: 2.4075\n",
            "Epoch 13: val_auc improved from 0.99072 to 0.99329, saving model to best_resnet50.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 2s/step - acc: 0.7604 - auc: 0.9270 - loss: 2.4067 - val_acc: 0.9219 - val_auc: 0.9933 - val_loss: 2.3041 - learning_rate: 1.0000e-04\n",
            "Epoch 14/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897ms/step - acc: 0.7879 - auc: 0.9380 - loss: 2.2857\n",
            "Epoch 14: val_auc improved from 0.99329 to 0.99453, saving model to best_resnet50.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 1s/step - acc: 0.7879 - auc: 0.9381 - loss: 2.2851 - val_acc: 0.9344 - val_auc: 0.9945 - val_loss: 2.1634 - learning_rate: 1.0000e-04\n",
            "Epoch 15/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891ms/step - acc: 0.7998 - auc: 0.9259 - loss: 2.2003\n",
            "Epoch 15: val_auc improved from 0.99453 to 0.99625, saving model to best_resnet50.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 1s/step - acc: 0.7999 - auc: 0.9263 - loss: 2.1992 - val_acc: 0.9172 - val_auc: 0.9962 - val_loss: 2.0627 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 15.\n",
            "\n",
            "[FASE 2] Fine-tuning (resnet50)\n",
            "Epoch 16/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.6454 - auc: 0.6140 - loss: 2.3906\n",
            "Epoch 16: val_auc improved from -inf to 0.52727, saving model to best_resnet50.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 2s/step - acc: 0.6460 - auc: 0.6154 - loss: 2.3896 - val_acc: 0.3562 - val_auc: 0.5273 - val_loss: 10.3725 - learning_rate: 1.0000e-05\n",
            "Epoch 17/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.7019 - auc: 0.7581 - loss: 2.2974\n",
            "Epoch 17: val_auc improved from 0.52727 to 0.55795, saving model to best_resnet50.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 2s/step - acc: 0.7023 - auc: 0.7591 - loss: 2.2963 - val_acc: 0.2984 - val_auc: 0.5579 - val_loss: 12.8854 - learning_rate: 1.0000e-05\n",
            "Epoch 18/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.7366 - auc: 0.8404 - loss: 2.1818\n",
            "Epoch 18: val_auc improved from 0.55795 to 0.57929, saving model to best_resnet50.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2s/step - acc: 0.7369 - auc: 0.8409 - loss: 2.1817 - val_acc: 0.3766 - val_auc: 0.5793 - val_loss: 7.5899 - learning_rate: 1.0000e-05\n",
            "Epoch 19/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.7589 - auc: 0.8422 - loss: 2.1821\n",
            "Epoch 19: val_auc improved from 0.57929 to 0.60158, saving model to best_resnet50.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2s/step - acc: 0.7589 - auc: 0.8428 - loss: 2.1815 - val_acc: 0.5156 - val_auc: 0.6016 - val_loss: 3.8241 - learning_rate: 1.0000e-05\n",
            "Epoch 20/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.7868 - auc: 0.9123 - loss: 2.1283\n",
            "Epoch 20: val_auc did not improve from 0.60158\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 2s/step - acc: 0.7867 - auc: 0.9124 - loss: 2.1278 - val_acc: 0.3734 - val_auc: 0.5701 - val_loss: 4.0276 - learning_rate: 1.0000e-05\n",
            "Epoch 21/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - acc: 0.7834 - auc: 0.9234 - loss: 2.0789\n",
            "Epoch 21: val_auc improved from 0.60158 to 0.63872, saving model to best_resnet50.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 3s/step - acc: 0.7835 - auc: 0.9235 - loss: 2.0793 - val_acc: 0.4203 - val_auc: 0.6387 - val_loss: 3.6355 - learning_rate: 1.0000e-05\n",
            "Epoch 22/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.7981 - auc: 0.9363 - loss: 2.0755\n",
            "Epoch 22: val_auc improved from 0.63872 to 0.79327, saving model to best_resnet50.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2s/step - acc: 0.7982 - auc: 0.9365 - loss: 2.0752 - val_acc: 0.4406 - val_auc: 0.7933 - val_loss: 3.2315 - learning_rate: 1.0000e-05\n",
            "Epoch 23/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - acc: 0.8150 - auc: 0.9360 - loss: 2.0448\n",
            "Epoch 23: val_auc improved from 0.79327 to 0.95118, saving model to best_resnet50.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 3s/step - acc: 0.8150 - auc: 0.9363 - loss: 2.0449 - val_acc: 0.5344 - val_auc: 0.9512 - val_loss: 2.7826 - learning_rate: 1.0000e-05\n",
            "Epoch 24/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - acc: 0.8065 - auc: 0.9396 - loss: 2.0492\n",
            "Epoch 24: val_auc improved from 0.95118 to 0.95127, saving model to best_resnet50.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 4s/step - acc: 0.8065 - auc: 0.9400 - loss: 2.0493 - val_acc: 0.5031 - val_auc: 0.9513 - val_loss: 2.9618 - learning_rate: 1.0000e-05\n",
            "Epoch 25/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - acc: 0.8215 - auc: 0.9474 - loss: 2.0277\n",
            "Epoch 25: val_auc improved from 0.95127 to 0.98141, saving model to best_resnet50.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 3s/step - acc: 0.8214 - auc: 0.9477 - loss: 2.0277 - val_acc: 0.4812 - val_auc: 0.9814 - val_loss: 2.8508 - learning_rate: 1.0000e-05\n",
            "Epoch 26/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.8116 - auc: 0.9509 - loss: 2.0355\n",
            "Epoch 26: val_auc improved from 0.98141 to 0.98807, saving model to best_resnet50.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 3s/step - acc: 0.8115 - auc: 0.9508 - loss: 2.0355 - val_acc: 0.6078 - val_auc: 0.9881 - val_loss: 2.7827 - learning_rate: 1.0000e-05\n",
            "Epoch 27/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.8140 - auc: 0.9462 - loss: 2.0440\n",
            "Epoch 27: val_auc improved from 0.98807 to 0.99146, saving model to best_resnet50.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 2s/step - acc: 0.8140 - auc: 0.9463 - loss: 2.0435 - val_acc: 0.8500 - val_auc: 0.9915 - val_loss: 2.1381 - learning_rate: 1.0000e-05\n",
            "Epoch 28/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.8289 - auc: 0.9715 - loss: 1.9865\n",
            "Epoch 28: val_auc improved from 0.99146 to 0.99428, saving model to best_resnet50.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - acc: 0.8288 - auc: 0.9716 - loss: 1.9866 - val_acc: 0.7844 - val_auc: 0.9943 - val_loss: 2.1860 - learning_rate: 1.0000e-05\n",
            "Epoch 29/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - acc: 0.8237 - auc: 0.9548 - loss: 2.0195\n",
            "Epoch 29: val_auc did not improve from 0.99428\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 4s/step - acc: 0.8236 - auc: 0.9550 - loss: 2.0189 - val_acc: 0.8422 - val_auc: 0.9919 - val_loss: 2.0332 - learning_rate: 1.0000e-05\n",
            "Epoch 30/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.8315 - auc: 0.9748 - loss: 1.9715\n",
            "Epoch 30: val_auc did not improve from 0.99428\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 3s/step - acc: 0.8316 - auc: 0.9749 - loss: 1.9713 - val_acc: 0.8969 - val_auc: 0.9843 - val_loss: 1.9364 - learning_rate: 1.0000e-05\n",
            "Epoch 31/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - acc: 0.8304 - auc: 0.9746 - loss: 1.9718\n",
            "Epoch 31: val_auc improved from 0.99428 to 0.99905, saving model to best_resnet50.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 4s/step - acc: 0.8304 - auc: 0.9747 - loss: 1.9715 - val_acc: 0.8828 - val_auc: 0.9990 - val_loss: 2.0000 - learning_rate: 1.0000e-05\n",
            "Epoch 32/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.8446 - auc: 0.9753 - loss: 1.9426\n",
            "Epoch 32: val_auc did not improve from 0.99905\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 2s/step - acc: 0.8447 - auc: 0.9756 - loss: 1.9423 - val_acc: 0.8016 - val_auc: 0.9962 - val_loss: 2.1579 - learning_rate: 1.0000e-05\n",
            "Epoch 33/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.8572 - auc: 0.9813 - loss: 1.9285\n",
            "Epoch 33: val_auc did not improve from 0.99905\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 3s/step - acc: 0.8571 - auc: 0.9814 - loss: 1.9285 - val_acc: 0.7766 - val_auc: 0.9855 - val_loss: 2.3411 - learning_rate: 1.0000e-05\n",
            "Epoch 34/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - acc: 0.8427 - auc: 0.9746 - loss: 1.9341\n",
            "Epoch 34: val_auc did not improve from 0.99905\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 3s/step - acc: 0.8426 - auc: 0.9749 - loss: 1.9342 - val_acc: 0.8781 - val_auc: 0.9989 - val_loss: 1.9335 - learning_rate: 1.0000e-05\n",
            "Epoch 35/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - acc: 0.8501 - auc: 0.9786 - loss: 1.9230\n",
            "Epoch 35: val_auc improved from 0.99905 to 0.99952, saving model to best_resnet50.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 4s/step - acc: 0.8501 - auc: 0.9787 - loss: 1.9229 - val_acc: 0.9078 - val_auc: 0.9995 - val_loss: 1.9004 - learning_rate: 1.0000e-05\n",
            "Epoch 36/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.8510 - auc: 0.9818 - loss: 1.9175\n",
            "Epoch 36: val_auc did not improve from 0.99952\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 2s/step - acc: 0.8509 - auc: 0.9819 - loss: 1.9176 - val_acc: 0.5422 - val_auc: 0.9972 - val_loss: 2.6746 - learning_rate: 1.0000e-05\n",
            "Epoch 37/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.8742 - auc: 0.9882 - loss: 1.8762\n",
            "Epoch 37: val_auc improved from 0.99952 to 1.00000, saving model to best_resnet50.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 2s/step - acc: 0.8740 - auc: 0.9883 - loss: 1.8764 - val_acc: 0.8172 - val_auc: 1.0000 - val_loss: 2.0535 - learning_rate: 1.0000e-05\n",
            "Epoch 38/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.8528 - auc: 0.9859 - loss: 1.8818\n",
            "Epoch 38: val_auc did not improve from 1.00000\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 3s/step - acc: 0.8528 - auc: 0.9859 - loss: 1.8819 - val_acc: 0.7641 - val_auc: 0.9967 - val_loss: 2.1876 - learning_rate: 1.0000e-05\n",
            "Epoch 39/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - acc: 0.8674 - auc: 0.9800 - loss: 1.8884\n",
            "Epoch 39: val_auc did not improve from 1.00000\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 4s/step - acc: 0.8672 - auc: 0.9803 - loss: 1.8881 - val_acc: 0.8422 - val_auc: 0.9993 - val_loss: 2.0411 - learning_rate: 1.0000e-05\n",
            "Epoch 40/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - acc: 0.8502 - auc: 0.9791 - loss: 1.8839\n",
            "Epoch 40: val_auc did not improve from 1.00000\n",
            "\n",
            "Epoch 40: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 4s/step - acc: 0.8504 - auc: 0.9795 - loss: 1.8833 - val_acc: 0.7953 - val_auc: 1.0000 - val_loss: 2.0359 - learning_rate: 1.0000e-05\n",
            "Epoch 41/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - acc: 0.8648 - auc: 0.9876 - loss: 1.8789\n",
            "Epoch 41: val_auc did not improve from 1.00000\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 3s/step - acc: 0.8648 - auc: 0.9878 - loss: 1.8785 - val_acc: 0.8250 - val_auc: 1.0000 - val_loss: 2.0041 - learning_rate: 5.0000e-06\n",
            "Epoch 42/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - acc: 0.8787 - auc: 0.9883 - loss: 1.8459\n",
            "Epoch 42: val_auc did not improve from 1.00000\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 4s/step - acc: 0.8786 - auc: 0.9885 - loss: 1.8458 - val_acc: 0.9125 - val_auc: 1.0000 - val_loss: 1.8512 - learning_rate: 5.0000e-06\n",
            "Epoch 43/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - acc: 0.8680 - auc: 0.9864 - loss: 1.8491\n",
            "Epoch 43: val_auc did not improve from 1.00000\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 4s/step - acc: 0.8681 - auc: 0.9866 - loss: 1.8490 - val_acc: 0.9563 - val_auc: 1.0000 - val_loss: 1.7819 - learning_rate: 5.0000e-06\n",
            "Epoch 44/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - acc: 0.8737 - auc: 0.9970 - loss: 1.8360\n",
            "Epoch 44: val_auc did not improve from 1.00000\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 4s/step - acc: 0.8738 - auc: 0.9970 - loss: 1.8359 - val_acc: 0.9406 - val_auc: 1.0000 - val_loss: 1.8034 - learning_rate: 5.0000e-06\n",
            "Epoch 45/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - acc: 0.8668 - auc: 0.9928 - loss: 1.8488\n",
            "Epoch 45: val_auc did not improve from 1.00000\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 4s/step - acc: 0.8668 - auc: 0.9928 - loss: 1.8485 - val_acc: 0.9641 - val_auc: 1.0000 - val_loss: 1.7788 - learning_rate: 5.0000e-06\n",
            "Epoch 46/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - acc: 0.8747 - auc: 0.9945 - loss: 1.8191\n",
            "Epoch 46: val_auc did not improve from 1.00000\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 4s/step - acc: 0.8748 - auc: 0.9945 - loss: 1.8194 - val_acc: 0.9828 - val_auc: 1.0000 - val_loss: 1.7436 - learning_rate: 5.0000e-06\n",
            "Epoch 47/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - acc: 0.8879 - auc: 0.9865 - loss: 1.8117\n",
            "Epoch 47: val_auc did not improve from 1.00000\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 4s/step - acc: 0.8876 - auc: 0.9867 - loss: 1.8120 - val_acc: 0.8781 - val_auc: 1.0000 - val_loss: 1.9017 - learning_rate: 5.0000e-06\n",
            "Epoch 48/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - acc: 0.8833 - auc: 0.9792 - loss: 1.8292\n",
            "Epoch 48: val_auc did not improve from 1.00000\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 4s/step - acc: 0.8833 - auc: 0.9796 - loss: 1.8291 - val_acc: 0.8453 - val_auc: 1.0000 - val_loss: 1.9064 - learning_rate: 5.0000e-06\n",
            "Epoch 49/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.8693 - auc: 0.9929 - loss: 1.8212\n",
            "Epoch 49: val_auc did not improve from 1.00000\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 3s/step - acc: 0.8692 - auc: 0.9929 - loss: 1.8213 - val_acc: 0.9875 - val_auc: 1.0000 - val_loss: 1.7500 - learning_rate: 5.0000e-06\n",
            "Epoch 49: early stopping\n",
            "Restoring model weights from the end of the best epoch: 37.\n",
            "\n",
            "[SUCESSO] Modelo resnet50 treinado e salvo\n",
            "\n",
            "============================================================\n",
            " TREINANDO MODELO: INCEPTIONV3 \n",
            "============================================================\n",
            "\n",
            "[FASE 1] Treinando cabeça classificadora (inceptionv3)\n",
            "Epoch 1/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682ms/step - acc: 0.5345 - auc: 0.5688 - loss: 8.7895\n",
            "Epoch 1: val_auc improved from -inf to 0.83714, saving model to best_inceptionv3.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 974ms/step - acc: 0.5355 - auc: 0.5711 - loss: 8.7841 - val_acc: 0.7203 - val_auc: 0.8371 - val_loss: 8.2315 - learning_rate: 1.0000e-04\n",
            "Epoch 2/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662ms/step - acc: 0.6318 - auc: 0.7943 - loss: 8.0496\n",
            "Epoch 2: val_auc improved from 0.83714 to 0.91343, saving model to best_inceptionv3.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 867ms/step - acc: 0.6319 - auc: 0.7947 - loss: 8.0465 - val_acc: 0.7625 - val_auc: 0.9134 - val_loss: 7.7515 - learning_rate: 1.0000e-04\n",
            "Epoch 3/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661ms/step - acc: 0.6907 - auc: 0.8871 - loss: 7.5490\n",
            "Epoch 3: val_auc improved from 0.91343 to 0.94880, saving model to best_inceptionv3.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 859ms/step - acc: 0.6907 - auc: 0.8873 - loss: 7.5463 - val_acc: 0.8313 - val_auc: 0.9488 - val_loss: 7.3181 - learning_rate: 1.0000e-04\n",
            "Epoch 4/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649ms/step - acc: 0.7055 - auc: 0.8960 - loss: 7.0898\n",
            "Epoch 4: val_auc improved from 0.94880 to 0.97778, saving model to best_inceptionv3.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 844ms/step - acc: 0.7055 - auc: 0.8964 - loss: 7.0879 - val_acc: 0.8594 - val_auc: 0.9778 - val_loss: 6.9138 - learning_rate: 1.0000e-04\n",
            "Epoch 5/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646ms/step - acc: 0.7217 - auc: 0.9196 - loss: 6.7244\n",
            "Epoch 5: val_auc improved from 0.97778 to 0.98773, saving model to best_inceptionv3.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 838ms/step - acc: 0.7219 - auc: 0.9197 - loss: 6.7221 - val_acc: 0.8625 - val_auc: 0.9877 - val_loss: 6.5336 - learning_rate: 1.0000e-04\n",
            "Epoch 6/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648ms/step - acc: 0.7499 - auc: 0.9266 - loss: 6.3415\n",
            "Epoch 6: val_auc improved from 0.98773 to 0.99138, saving model to best_inceptionv3.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 840ms/step - acc: 0.7499 - auc: 0.9268 - loss: 6.3396 - val_acc: 0.8859 - val_auc: 0.9914 - val_loss: 6.1728 - learning_rate: 1.0000e-04\n",
            "Epoch 7/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648ms/step - acc: 0.7575 - auc: 0.9389 - loss: 6.0008\n",
            "Epoch 7: val_auc improved from 0.99138 to 0.99613, saving model to best_inceptionv3.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 841ms/step - acc: 0.7576 - auc: 0.9390 - loss: 5.9992 - val_acc: 0.8906 - val_auc: 0.9961 - val_loss: 5.8350 - learning_rate: 1.0000e-04\n",
            "Epoch 8/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639ms/step - acc: 0.7621 - auc: 0.9606 - loss: 5.6880\n",
            "Epoch 8: val_auc improved from 0.99613 to 0.99694, saving model to best_inceptionv3.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 833ms/step - acc: 0.7624 - auc: 0.9606 - loss: 5.6861 - val_acc: 0.9062 - val_auc: 0.9969 - val_loss: 5.5123 - learning_rate: 1.0000e-04\n",
            "Epoch 9/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657ms/step - acc: 0.7711 - auc: 0.9523 - loss: 5.4014\n",
            "Epoch 9: val_auc improved from 0.99694 to 0.99831, saving model to best_inceptionv3.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 851ms/step - acc: 0.7711 - auc: 0.9526 - loss: 5.3994 - val_acc: 0.9141 - val_auc: 0.9983 - val_loss: 5.2048 - learning_rate: 1.0000e-04\n",
            "Epoch 10/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657ms/step - acc: 0.8003 - auc: 0.9707 - loss: 5.0719\n",
            "Epoch 10: val_auc improved from 0.99831 to 1.00000, saving model to best_inceptionv3.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 851ms/step - acc: 0.8003 - auc: 0.9707 - loss: 5.0710 - val_acc: 0.9375 - val_auc: 1.0000 - val_loss: 4.9214 - learning_rate: 1.0000e-04\n",
            "Epoch 11/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656ms/step - acc: 0.8069 - auc: 0.9748 - loss: 4.8426\n",
            "Epoch 11: val_auc did not improve from 1.00000\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 822ms/step - acc: 0.8067 - auc: 0.9748 - loss: 4.8408 - val_acc: 0.9281 - val_auc: 1.0000 - val_loss: 4.6533 - learning_rate: 1.0000e-04\n",
            "Epoch 12/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655ms/step - acc: 0.8062 - auc: 0.9739 - loss: 4.5943\n",
            "Epoch 12: val_auc did not improve from 1.00000\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 820ms/step - acc: 0.8063 - auc: 0.9741 - loss: 4.5926 - val_acc: 0.9172 - val_auc: 1.0000 - val_loss: 4.4057 - learning_rate: 1.0000e-04\n",
            "Epoch 13/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654ms/step - acc: 0.8140 - auc: 0.9781 - loss: 4.3642\n",
            "Epoch 13: val_auc did not improve from 1.00000\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 826ms/step - acc: 0.8138 - auc: 0.9780 - loss: 4.3628 - val_acc: 0.9062 - val_auc: 1.0000 - val_loss: 4.1834 - learning_rate: 1.0000e-04\n",
            "Epoch 14/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653ms/step - acc: 0.8242 - auc: 0.9701 - loss: 4.1524\n",
            "Epoch 14: val_auc did not improve from 1.00000\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 819ms/step - acc: 0.8240 - auc: 0.9703 - loss: 4.1508 - val_acc: 0.9141 - val_auc: 1.0000 - val_loss: 3.9553 - learning_rate: 1.0000e-04\n",
            "Epoch 15/15\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646ms/step - acc: 0.8315 - auc: 0.9778 - loss: 3.9183\n",
            "Epoch 15: val_auc did not improve from 1.00000\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 813ms/step - acc: 0.8315 - auc: 0.9779 - loss: 3.9173 - val_acc: 0.9187 - val_auc: 1.0000 - val_loss: 3.7528 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\n",
            "[FASE 2] Fine-tuning (inceptionv3)\n",
            "Epoch 16/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - acc: 0.6196 - auc: 0.6745 - loss: 5.1902\n",
            "Epoch 16: val_auc improved from -inf to 0.99590, saving model to best_inceptionv3.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 1s/step - acc: 0.6201 - auc: 0.6754 - loss: 5.1896 - val_acc: 0.8609 - val_auc: 0.9959 - val_loss: 4.9037 - learning_rate: 1.0000e-05\n",
            "Epoch 17/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - acc: 0.6881 - auc: 0.8273 - loss: 5.0410\n",
            "Epoch 17: val_auc did not improve from 0.99590\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 1s/step - acc: 0.6883 - auc: 0.8275 - loss: 5.0409 - val_acc: 0.8234 - val_auc: 0.9762 - val_loss: 4.9199 - learning_rate: 1.0000e-05\n",
            "Epoch 18/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - acc: 0.7109 - auc: 0.8375 - loss: 4.9985\n",
            "Epoch 18: val_auc did not improve from 0.99590\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 1s/step - acc: 0.7113 - auc: 0.8382 - loss: 4.9980 - val_acc: 0.8531 - val_auc: 0.9860 - val_loss: 4.9004 - learning_rate: 1.0000e-05\n",
            "Epoch 19/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - acc: 0.7512 - auc: 0.9004 - loss: 4.9265\n",
            "Epoch 19: val_auc did not improve from 0.99590\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 1s/step - acc: 0.7510 - auc: 0.9005 - loss: 4.9264 - val_acc: 0.8453 - val_auc: 0.9875 - val_loss: 4.8489 - learning_rate: 1.0000e-05\n",
            "Epoch 20/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - acc: 0.7655 - auc: 0.9234 - loss: 4.8768\n",
            "Epoch 20: val_auc did not improve from 0.99590\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 1s/step - acc: 0.7653 - auc: 0.9234 - loss: 4.8769 - val_acc: 0.8375 - val_auc: 0.9941 - val_loss: 4.8255 - learning_rate: 1.0000e-05\n",
            "Epoch 21/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - acc: 0.7718 - auc: 0.9248 - loss: 4.8421\n",
            "Epoch 21: val_auc improved from 0.99590 to 0.99824, saving model to best_inceptionv3.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - acc: 0.7717 - auc: 0.9252 - loss: 4.8420 - val_acc: 0.8438 - val_auc: 0.9982 - val_loss: 4.8096 - learning_rate: 1.0000e-05\n",
            "Epoch 22/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.7518 - auc: 0.9301 - loss: 4.8341\n",
            "Epoch 22: val_auc improved from 0.99824 to 0.99946, saving model to best_inceptionv3.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2s/step - acc: 0.7521 - auc: 0.9305 - loss: 4.8337 - val_acc: 0.8219 - val_auc: 0.9995 - val_loss: 4.7927 - learning_rate: 1.0000e-05\n",
            "Epoch 23/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.7713 - auc: 0.9394 - loss: 4.7879\n",
            "Epoch 23: val_auc improved from 0.99946 to 1.00000, saving model to best_inceptionv3.keras\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - acc: 0.7715 - auc: 0.9398 - loss: 4.7877 - val_acc: 0.8141 - val_auc: 1.0000 - val_loss: 4.7526 - learning_rate: 1.0000e-05\n",
            "Epoch 24/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - acc: 0.7870 - auc: 0.9609 - loss: 4.7242\n",
            "Epoch 24: val_auc did not improve from 1.00000\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 1s/step - acc: 0.7871 - auc: 0.9611 - loss: 4.7243 - val_acc: 0.8156 - val_auc: 1.0000 - val_loss: 4.7349 - learning_rate: 1.0000e-05\n",
            "Epoch 25/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - acc: 0.7904 - auc: 0.9534 - loss: 4.7412\n",
            "Epoch 25: val_auc did not improve from 1.00000\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 1s/step - acc: 0.7903 - auc: 0.9536 - loss: 4.7411 - val_acc: 0.8422 - val_auc: 1.0000 - val_loss: 4.7155 - learning_rate: 1.0000e-05\n",
            "Epoch 26/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - acc: 0.7772 - auc: 0.9584 - loss: 4.6872\n",
            "Epoch 26: val_auc did not improve from 1.00000\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 1s/step - acc: 0.7775 - auc: 0.9587 - loss: 4.6875 - val_acc: 0.8500 - val_auc: 1.0000 - val_loss: 4.6833 - learning_rate: 1.0000e-05\n",
            "Epoch 27/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - acc: 0.7843 - auc: 0.9546 - loss: 4.6806\n",
            "Epoch 27: val_auc did not improve from 1.00000\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 1s/step - acc: 0.7844 - auc: 0.9550 - loss: 4.6806 - val_acc: 0.8687 - val_auc: 1.0000 - val_loss: 4.6437 - learning_rate: 1.0000e-05\n",
            "Epoch 28/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.8126 - auc: 0.9759 - loss: 4.6385\n",
            "Epoch 28: val_auc did not improve from 1.00000\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - acc: 0.8125 - auc: 0.9760 - loss: 4.6384 - val_acc: 0.8687 - val_auc: 1.0000 - val_loss: 4.6192 - learning_rate: 1.0000e-05\n",
            "Epoch 29/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - acc: 0.8057 - auc: 0.9678 - loss: 4.6323\n",
            "Epoch 29: val_auc did not improve from 1.00000\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 1s/step - acc: 0.8056 - auc: 0.9681 - loss: 4.6318 - val_acc: 0.8797 - val_auc: 1.0000 - val_loss: 4.5858 - learning_rate: 1.0000e-05\n",
            "Epoch 30/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.8132 - auc: 0.9775 - loss: 4.6051\n",
            "Epoch 30: val_auc did not improve from 1.00000\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 2s/step - acc: 0.8130 - auc: 0.9777 - loss: 4.6049 - val_acc: 0.8797 - val_auc: 1.0000 - val_loss: 4.5620 - learning_rate: 1.0000e-05\n",
            "Epoch 31/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.8145 - auc: 0.9771 - loss: 4.5445\n",
            "Epoch 31: val_auc did not improve from 1.00000\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 3s/step - acc: 0.8144 - auc: 0.9772 - loss: 4.5448 - val_acc: 0.8734 - val_auc: 1.0000 - val_loss: 4.5346 - learning_rate: 1.0000e-05\n",
            "Epoch 32/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.8283 - auc: 0.9864 - loss: 4.5439\n",
            "Epoch 32: val_auc did not improve from 1.00000\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 3s/step - acc: 0.8282 - auc: 0.9864 - loss: 4.5436 - val_acc: 0.8813 - val_auc: 1.0000 - val_loss: 4.5126 - learning_rate: 1.0000e-05\n",
            "Epoch 33/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.8067 - auc: 0.9788 - loss: 4.5299\n",
            "Epoch 33: val_auc did not improve from 1.00000\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 3s/step - acc: 0.8069 - auc: 0.9790 - loss: 4.5296 - val_acc: 0.8781 - val_auc: 1.0000 - val_loss: 4.4959 - learning_rate: 1.0000e-05\n",
            "Epoch 34/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.8152 - auc: 0.9861 - loss: 4.5163\n",
            "Epoch 34: val_auc did not improve from 1.00000\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 3s/step - acc: 0.8154 - auc: 0.9862 - loss: 4.5156 - val_acc: 0.8813 - val_auc: 1.0000 - val_loss: 4.4688 - learning_rate: 1.0000e-05\n",
            "Epoch 35/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.8131 - auc: 0.9865 - loss: 4.4834\n",
            "Epoch 35: val_auc did not improve from 1.00000\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 2s/step - acc: 0.8132 - auc: 0.9866 - loss: 4.4832 - val_acc: 0.8687 - val_auc: 1.0000 - val_loss: 4.4512 - learning_rate: 1.0000e-05\n",
            "Epoch 35: early stopping\n",
            "Restoring model weights from the end of the best epoch: 23.\n",
            "\n",
            "[SUCESSO] Modelo inceptionv3 treinado e salvo\n",
            "\n",
            "[INFO] Avaliando ensemble de modelos...\n",
            "[AVISO] Funções de métricas não disponíveis! Reimportando...\n",
            "\n",
            "[RESULTADOS DO ENSEMBLE POR DEFEITO]\n",
            "  - CONTENT_HIGH: Acurácia = 1.0000, F1 = 1.0000\n",
            "  - CONTENT_LOW: Acurácia = 0.8875, F1 = 0.7273\n",
            "  - COVER_NONE: Acurácia = 0.7875, F1 = 0.7302\n",
            "  - BOTTLE_SMASHED: Acurácia = 0.8750, F1 = 0.7222\n",
            "  - LABEL_WHITE: Acurácia = 0.7875, F1 = 0.5405\n",
            "  - LABEL_MISPLACED: Acurácia = 0.7625, F1 = 0.5957\n",
            "  - LABEL_NONE: Acurácia = 0.8750, F1 = 0.7059\n",
            "  - BOTTLE_NONE: Acurácia = 0.9000, F1 = 0.7143\n",
            "\n",
            "[RESULTADO FINAL] Acurácia média: 0.8594, F1 médio: 0.7170\n",
            "\n",
            "[SUCESSO] Ensemble treinado e salvo com relatório completo\n",
            "[META] Acurácia alcançada: 85.94%\n",
            "\n",
            "============================================================\n",
            " PROCESSO CONCLUÍDO COM SUCESSO \n",
            "============================================================\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1400x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# CONFIGURAÇÃO OTIMIZADA DE GPU\n",
        "# =============================================================================\n",
        "\n",
        "# Configuração otimizada de GPU\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(f\"[GPU] Configuração ativada para: {gpus}\")\n",
        "    except RuntimeError as e:\n",
        "        print(f\"[ERRO GPU] Configuração falhou: {e}\")\n",
        "\n",
        "# Habilitar precisão mista\n",
        "try:\n",
        "    tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "    print(\"[INFO] Precisão mista ativada.\")\n",
        "except RuntimeError as e:\n",
        "    print(f\"[ERRO] Não foi possível ativar precisão mista: {e}\")\n",
        "\n",
        "# =============================================================================\n",
        "# CONFIGURAÇÕES GLOBAIS OTIMIZADAS\n",
        "# =============================================================================\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "BATCH_SIZE = 8\n",
        "IMG_SIZE = (512, 512)\n",
        "DATA_DIR = r'C:\\Users\\fabia\\Downloads\\manufacturing-quality-control'\n",
        "TARGET_SAMPLES = 50\n",
        "DENSE_UNITS = 512\n",
        "DROPOUT_RATE = 0.6\n",
        "EPOCHS = 50\n",
        "INIT_LR = 0.0001\n",
        "MIN_LR = 1e-7\n",
        "\n",
        "# LISTA COMPLETA DE DEFEITOS (8 CLASSES)\n",
        "DEFECTS = [\n",
        "    'CONTENT_HIGH',\n",
        "    'CONTENT_LOW',\n",
        "    'COVER_NONE',\n",
        "    'BOTTLE_SMASHED',\n",
        "    'LABEL_WHITE',\n",
        "    'LABEL_MISPLACED',\n",
        "    'LABEL_NONE',\n",
        "    'BOTTLE_NONE'\n",
        "]\n",
        "NUM_CLASSES = len(DEFECTS)\n",
        "\n",
        "# =============================================================================\n",
        "# FUNÇÕES DE PRÉ-PROCESSAMENTO AVANÇADAS (SIMPLIFICADAS)\n",
        "# =============================================================================\n",
        "def load_and_preprocess_image(path, target_size=IMG_SIZE):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, target_size)\n",
        "    img = tf.cast(img, tf.float32) / 255.0\n",
        "    return img\n",
        "\n",
        "def apply_defect_focused_augmentation(image, label):\n",
        "    \"\"\"Aumento de dados simplificado usando operações nativas\"\"\"\n",
        "    # Flip horizontal\n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        image = tf.image.flip_left_right(image)\n",
        "    \n",
        "    # Ajustes de brilho e contraste\n",
        "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
        "    image = tf.image.random_contrast(image, lower=0.9, upper=1.1)\n",
        "    image = tf.clip_by_value(image, 0.0, 1.0)\n",
        "    \n",
        "    # Ruído gaussiano\n",
        "    if tf.random.uniform(()) > 0.6:\n",
        "        noise = tf.random.normal(shape=tf.shape(image), mean=0.0, stddev=0.02)\n",
        "        image = image + noise\n",
        "        image = tf.clip_by_value(image, 0.0, 1.0)\n",
        "    \n",
        "    return image, label\n",
        "\n",
        "# =============================================================================\n",
        "# ARQUITETURAS DE MODELOS AVANÇADOS\n",
        "# =============================================================================\n",
        "def create_model(base_arch, model_name):\n",
        "    \"\"\"Cria modelo com arquitetura específica\"\"\"\n",
        "    base_model = base_arch(\n",
        "        include_top=False,\n",
        "        weights='imagenet',\n",
        "        input_shape=(*IMG_SIZE, 3),\n",
        "        pooling='avg'\n",
        "    )\n",
        "    base_model.trainable = False\n",
        "    \n",
        "    inputs = tf.keras.Input(shape=(*IMG_SIZE, 3), dtype=tf.float32)\n",
        "    x = base_model(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dense(DENSE_UNITS, activation='relu', \n",
        "                    kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "    x = layers.Dropout(DROPOUT_RATE)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    outputs = layers.Dense(NUM_CLASSES, activation='sigmoid', dtype=tf.float32)(x)\n",
        "    \n",
        "    model = tf.keras.Model(inputs, outputs, name=model_name)\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=INIT_LR),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[\n",
        "            tf.keras.metrics.BinaryAccuracy(name='acc'),\n",
        "            tf.keras.metrics.AUC(name='auc', multi_label=True)\n",
        "        ]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def unfreeze_model(model, unfreeze_percentage=0.4):\n",
        "    \"\"\"Descongela uma porcentagem das camadas do modelo base\"\"\"\n",
        "    base_model = model.layers[1]\n",
        "    total_layers = len(base_model.layers)\n",
        "    unfreeze_from = int(total_layers * (1 - unfreeze_percentage))\n",
        "    \n",
        "    # Primeiro, descongelamos todas as camadas, mas depois congelamos até a camada unfreeze_from\n",
        "    base_model.trainable = True\n",
        "    for layer in base_model.layers[:unfreeze_from]:\n",
        "        layer.trainable = False\n",
        "    \n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=INIT_LR/10),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[\n",
        "            tf.keras.metrics.BinaryAccuracy(name='acc'),\n",
        "            tf.keras.metrics.AUC(name='auc', multi_label=True)\n",
        "        ]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# =============================================================================\n",
        "# PIPELINE PRINCIPAL AVANÇADO (CORRIGIDO)\n",
        "# =============================================================================\n",
        "def main():\n",
        "    tf.keras.backend.clear_session()\n",
        "    gc.collect()\n",
        "    \n",
        "    # 1. CARREGAR METADADOS\n",
        "    train_csv_path = os.path.join(DATA_DIR, 'train.csv')\n",
        "    if not os.path.exists(train_csv_path):\n",
        "        raise FileNotFoundError(f\"Arquivo train.csv não encontrado em: {train_csv_path}\")\n",
        "    \n",
        "    train_df = pd.read_csv(train_csv_path).fillna(0)\n",
        "    \n",
        "    for defect in DEFECTS:\n",
        "        if defect not in train_df.columns:\n",
        "            train_df[defect] = 0\n",
        "    \n",
        "    print(f\"[INFO] Distribuição original de defeitos:\")\n",
        "    print(train_df[DEFECTS].sum())\n",
        "    \n",
        "    # 2. GERAR LISTA DE CAMINHOS E LABELS (CORREÇÃO: BUSCA DIRETA DE IMAGENS)\n",
        "    image_paths = []\n",
        "    image_labels = []\n",
        "    train_dir = os.path.join(DATA_DIR, 'train')\n",
        "    \n",
        "    if not os.path.exists(train_dir):\n",
        "        raise FileNotFoundError(f\"Diretório de imagens não encontrado: {train_dir}\")\n",
        "    \n",
        "    # Lista todos os arquivos de imagem no diretório\n",
        "    valid_extensions = ['.jpg', '.jpeg', '.png']\n",
        "    image_files = [f for f in os.listdir(train_dir) \n",
        "                  if os.path.splitext(f)[1].lower() in valid_extensions]\n",
        "    \n",
        "    if not image_files:\n",
        "        raise ValueError(\"Nenhuma imagem encontrada no diretório de treino\")\n",
        "    \n",
        "    print(f\"[INFO] Total de imagens encontradas: {len(image_files)}\")\n",
        "    \n",
        "    # Mapeia IDs das imagens para caminhos completos\n",
        "    file_id_to_path = {}\n",
        "    for img_file in image_files:\n",
        "        file_id = os.path.splitext(img_file)[0]\n",
        "        file_id_to_path[file_id] = os.path.join(train_dir, img_file)\n",
        "    \n",
        "    # Associa imagens com metadados\n",
        "    for idx, row in train_df.iterrows():\n",
        "        img_id = str(row['id'])\n",
        "        \n",
        "        # Remove extensão se presente\n",
        "        img_id_base = os.path.splitext(img_id)[0]\n",
        "        \n",
        "        if img_id_base in file_id_to_path:\n",
        "            image_paths.append(file_id_to_path[img_id_base])\n",
        "            image_labels.append(row[DEFECTS].values.astype(np.float32))\n",
        "        else:\n",
        "            print(f\"[AVISO] Metadados não encontrados para: {img_id}\")\n",
        "    \n",
        "    if not image_paths:\n",
        "        raise ValueError(\"Nenhuma correspondência entre imagens e metadados encontrada\")\n",
        "    \n",
        "    print(f\"[INFO] Total de imagens com metadados: {len(image_paths)}\")\n",
        "    \n",
        "    # 3. BALANCEAMENTO E CÁLCULO DE PESOS\n",
        "    class_counts = {i: 0 for i in range(NUM_CLASSES)}\n",
        "    for label_vec in image_labels:\n",
        "        for class_idx in np.where(label_vec == 1)[0]:\n",
        "            class_counts[class_idx] += 1\n",
        "    \n",
        "    total_samples = len(image_labels)\n",
        "    class_weights = {}\n",
        "    for class_idx in class_counts:\n",
        "        if class_counts[class_idx] > 0:\n",
        "            weight = (1 / class_counts[class_idx]) * (total_samples / NUM_CLASSES)\n",
        "            class_weights[class_idx] = min(weight, 5.0)\n",
        "        else:\n",
        "            class_weights[class_idx] = 1.0\n",
        "    \n",
        "    print(\"\\n[INFO] Pesos de classe para balanceamento:\")\n",
        "    for i, defect in enumerate(DEFECTS):\n",
        "        print(f\"  - {defect}: {class_weights[i]:.2f} (amostras: {class_counts[i]})\")\n",
        "    \n",
        "    # 4. BALANCEAMENTO DE AMOSTRAS\n",
        "    class_indices = {i: [] for i in range(NUM_CLASSES)}\n",
        "    for idx, label_vec in enumerate(image_labels):\n",
        "        for class_idx in np.where(label_vec == 1)[0]:\n",
        "            class_indices[class_idx].append(idx)\n",
        "    \n",
        "    balanced_indices = []\n",
        "    for class_idx, indices in class_indices.items():\n",
        "        balanced_indices.extend(indices)\n",
        "        need = max(0, TARGET_SAMPLES - len(indices))\n",
        "        \n",
        "        if need > 0 and len(indices) > 0:\n",
        "            synth_indices = np.random.choice(indices, size=need, replace=True)\n",
        "            balanced_indices.extend(synth_indices)\n",
        "    \n",
        "    print(f\"[INFO] Total de amostras após balanceamento: {len(balanced_indices)}\")\n",
        "    \n",
        "    # 5. PREPARAR DATASET\n",
        "    print(\"\\n[INFO] Carregando imagens em memória...\")\n",
        "    images = []\n",
        "    for path in [image_paths[i] for i in balanced_indices]:\n",
        "        img = load_and_preprocess_image(path)\n",
        "        images.append(img.numpy())\n",
        "    \n",
        "    images = np.array(images)\n",
        "    labels = np.array([image_labels[i] for i in balanced_indices], dtype=np.float32)\n",
        "    \n",
        "    print(f\"[INFO] Dataset balanceado - Imagens: {images.shape}, Labels: {labels.shape}\")\n",
        "    \n",
        "    # 6. DIVISÃO TREINO/VALIDAÇÃO\n",
        "    try:\n",
        "        # Usamos a classe mais frequente para estratificação\n",
        "        dominant_class = np.argmax(labels, axis=1)\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            images, labels, \n",
        "            test_size=0.2, \n",
        "            random_state=42,\n",
        "            stratify=dominant_class\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"[AVISO] Erro na estratificação: {str(e)} - Usando divisão aleatória\")\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            images, labels, \n",
        "            test_size=0.2, \n",
        "            random_state=42\n",
        "        )\n",
        "    \n",
        "    # 7. CRIAR DATASETS\n",
        "    def augment_train(image, label):\n",
        "        return apply_defect_focused_augmentation(image, label)\n",
        "    \n",
        "    train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "    train_ds = train_ds.map(augment_train, num_parallel_calls=AUTOTUNE)\n",
        "    train_ds = train_ds.shuffle(1000).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "    \n",
        "    val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
        "    val_ds = val_ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "    \n",
        "    # 8. CALLBACKS AVANÇADOS\n",
        "    def get_callbacks(model_name):\n",
        "        return [\n",
        "            ModelCheckpoint(\n",
        "                f'best_{model_name}.keras',\n",
        "                save_best_only=True,\n",
        "                monitor='val_auc',\n",
        "                mode='max',\n",
        "                verbose=1\n",
        "            ),\n",
        "            EarlyStopping(\n",
        "                patience=12,\n",
        "                monitor='val_auc',\n",
        "                mode='max',\n",
        "                restore_best_weights=True,\n",
        "                verbose=1\n",
        "            ),\n",
        "            ReduceLROnPlateau(\n",
        "                monitor='val_loss',\n",
        "                factor=0.5,\n",
        "                patience=5,\n",
        "                min_lr=MIN_LR,\n",
        "                verbose=1\n",
        "            )\n",
        "        ]\n",
        "    \n",
        "    # 9. TREINAMENTO DOS MODELOS BASE\n",
        "    print(\"\\n[INFO] Treinando modelos base para ensemble...\")\n",
        "    \n",
        "    model_archs = {\n",
        "        'efficientnet': (EfficientNetB0, 'efficientnet'),\n",
        "        'resnet50': (ResNet50, 'resnet50'),\n",
        "        'inceptionv3': (InceptionV3, 'inceptionv3')\n",
        "    }\n",
        "    \n",
        "    trained_models = {}\n",
        "    \n",
        "    for model_key, (base_arch, model_name) in model_archs.items():\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\" TREINANDO MODELO: {model_name.upper()} \")\n",
        "        print(f\"{'='*60}\")\n",
        "        \n",
        "        model = create_model(base_arch, model_name)\n",
        "        \n",
        "        # Fase 1: Treinar apenas a cabeça\n",
        "        print(f\"\\n[FASE 1] Treinando cabeça classificadora ({model_name})\")\n",
        "        history1 = model.fit(\n",
        "            train_ds,\n",
        "            validation_data=val_ds,\n",
        "            epochs=15,\n",
        "            callbacks=get_callbacks(model_name),\n",
        "            class_weight=class_weights,\n",
        "            verbose=1\n",
        "        )\n",
        "        \n",
        "        # Fase 2: Fine-tuning se performance for boa\n",
        "        if max(history1.history['val_auc']) > 0.75:\n",
        "            print(f\"\\n[FASE 2] Fine-tuning ({model_name})\")\n",
        "            model = unfreeze_model(model, unfreeze_percentage=0.4)\n",
        "            \n",
        "            history2 = model.fit(\n",
        "                train_ds,\n",
        "                validation_data=val_ds,\n",
        "                initial_epoch=15,\n",
        "                epochs=EPOCHS,\n",
        "                callbacks=get_callbacks(model_name),\n",
        "                class_weight=class_weights,\n",
        "                verbose=1\n",
        "            )\n",
        "        else:\n",
        "            print(f\"\\n[AVISO] Performance insatisfatória na Fase 1 para {model_name}. Pulando fine-tuning.\")\n",
        "        \n",
        "        model.save(f'{model_name}_model.keras')\n",
        "        trained_models[model_name] = model\n",
        "        print(f\"\\n[SUCESSO] Modelo {model_name} treinado e salvo\")\n",
        "    \n",
        "    # 10. ENSEMBLE E AVALIAÇÃO FINAL\n",
        "    print(\"\\n[INFO] Avaliando ensemble de modelos...\")\n",
        "    \n",
        "    # Prever usando ensemble\n",
        "    def ensemble_predict(models, X):\n",
        "        preds = np.zeros((X.shape[0], NUM_CLASSES))\n",
        "        for name, model in models.items():\n",
        "            preds += model.predict(X, verbose=0)\n",
        "        return preds / len(models)\n",
        "    \n",
        "    # Previsões e métricas\n",
        "    y_pred_ensemble = ensemble_predict(trained_models, X_val)\n",
        "    y_pred_binary = (y_pred_ensemble > 0.5).astype(int)\n",
        "    \n",
        "    # VERIFICAÇÃO DE SEGURANÇA PARA AS MÉTRICAS\n",
        "    try:\n",
        "        # Teste preliminar das funções de métrica\n",
        "        test_score = accuracy_score([0,1], [0,1])\n",
        "        test_f1 = f1_score([0,1], [0,1])\n",
        "    except NameError:\n",
        "        print(\"[AVISO] Funções de métricas não disponíveis! Reimportando...\")\n",
        "        from sklearn.metrics import accuracy_score, f1_score\n",
        "    \n",
        "    # Métricas por classe\n",
        "    acc_scores = {}\n",
        "    f1_scores = {}\n",
        "    \n",
        "    for i, defect in enumerate(DEFECTS):\n",
        "        try:\n",
        "            acc = accuracy_score(y_val[:, i], y_pred_binary[:, i])\n",
        "            f1_val = f1_score(y_val[:, i], y_pred_binary[:, i])  # Variável renomeada para evitar conflito\n",
        "        except Exception as e:\n",
        "            print(f\"[ERRO] Falha ao calcular métricas para {defect}: {str(e)}\")\n",
        "            acc = 0.0\n",
        "            f1_val = 0.0\n",
        "        \n",
        "        acc_scores[defect] = acc\n",
        "        f1_scores[defect] = f1_val\n",
        "\n",
        "    print(\"\\n[RESULTADOS DO ENSEMBLE POR DEFEITO]\")\n",
        "    for defect in DEFECTS:\n",
        "        print(f\"  - {defect}: Acurácia = {acc_scores[defect]:.4f}, F1 = {f1_scores[defect]:.4f}\")\n",
        "    \n",
        "    mean_acc = np.mean(list(acc_scores.values()))\n",
        "    mean_f1 = np.mean(list(f1_scores.values()))\n",
        "    print(f\"\\n[RESULTADO FINAL] Acurácia média: {mean_acc:.4f}, F1 médio: {mean_f1:.4f}\")\n",
        "    \n",
        "    # 11. SALVAR ENSEMBLE E RELATÓRIO\n",
        "    ensemble_dir = 'ensemble_models'\n",
        "    os.makedirs(ensemble_dir, exist_ok=True)\n",
        "    for name, model in trained_models.items():\n",
        "        model.save(os.path.join(ensemble_dir, f'{name}_model.keras'))\n",
        "    \n",
        "    with open('ensemble_performance.txt', 'w') as f:\n",
        "        f.write(\"Relatório de Desempenho do Ensemble\\n\")\n",
        "        f.write(\"==================================\\n\\n\")\n",
        "        f.write(f\"Acurácia média: {mean_acc:.4f}\\n\")\n",
        "        f.write(f\"F1 médio: {mean_f1:.4f}\\n\\n\")\n",
        "        f.write(\"Desempenho por defeito:\\n\")\n",
        "        for defect in DEFECTS:\n",
        "            f.write(f\"  - {defect}: Acurácia = {acc_scores[defect]:.4f}, F1 = {f1_scores[defect]:.4f}\\n\")\n",
        "    \n",
        "    # Plotar comparação\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    \n",
        "    # Acurácia por modelo\n",
        "    plt.subplot(1, 2, 1)\n",
        "    model_names = list(trained_models.keys())\n",
        "    model_accs = []\n",
        "    for name, model in trained_models.items():\n",
        "        _, acc, _ = model.evaluate(X_val, y_val, verbose=0)\n",
        "        model_accs.append(acc)\n",
        "        plt.bar(name, acc)\n",
        "    \n",
        "    plt.bar('Ensemble', mean_acc, color='purple')\n",
        "    plt.title('Comparação de Acurácia dos Modelos')\n",
        "    plt.ylabel('Acurácia')\n",
        "    plt.ylim(0.5, 1.0)\n",
        "    \n",
        "    # Acurácia por defeito\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.bar(DEFECTS, list(acc_scores.values()))\n",
        "    plt.title('Acurácia por Tipo de Defeito')\n",
        "    plt.ylabel('Acurácia')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.ylim(0.5, 1.0)\n",
        "    plt.tight_layout()\n",
        "    \n",
        "    plt.savefig('model_comparison.png', bbox_inches='tight')\n",
        "    \n",
        "    print(\"\\n[SUCESSO] Ensemble treinado e salvo com relatório completo\")\n",
        "    print(f\"[META] Acurácia alcançada: {mean_acc*100:.2f}%\")\n",
        "\n",
        "# EXECUÇÃO\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\" SISTEMA AVANÇADO DE ENSEMBLE PARA CONTROLE DE QUALIDADE\")\n",
        "    print(f\" CLASSIFICANDO {NUM_CLASSES} TIPOS DE DEFEITOS\")\n",
        "    print(\" META: 90%+ DE ACURÁCIA\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    try:\n",
        "        main()\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\" PROCESSO CONCLUÍDO COM SUCESSO \")\n",
        "        print(\"=\"*60)\n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\" ERRO NO PROCESSAMENTO \")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"Detalhes do erro: {str(e)}\")\n",
        "        print(\"\\nTraceback completo:\")\n",
        "        traceback.print_exc()\n",
        "        print(\"\\nSolução recomendada:\")\n",
        "        print(\"1. Verifique os caminhos dos arquivos\")\n",
        "        print(\"2. Reduza o IMG_SIZE para 384x384 se necessário\")\n",
        "        print(\"3. Reduza o BATCH_SIZE para 4\")\n",
        "        print(\"4. Verifique espaço em disco (mínimo 10GB livre)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[INFO] Gerando submissão com o melhor modelo (ensemble)...\n",
            "[SUCESSO] Arquivo de submissão gerado: C:\\Users\\fabia\\Downloads\\sample_submission.csv\n",
            "         Total de imagens processadas: 64\n",
            "         Imagens faltantes: 0\n",
            "\n",
            "[INFO] Submissão gerada com sucesso!\n",
            "  - Arquivo: C:\\Users\\fabia\\Downloads\\sample_submission.csv\n",
            "  - Modelo usado: Ensemble completo\n",
            "\n",
            "[VERIFICAÇÃO] Primeiras linhas do arquivo gerado:\n",
            "           id  CONTENT_HIGH  CONTENT_LOW  COVER_NONE  BOTTLE_SMASHED  \\\n",
            "0  test_1.jpg             1            1           1               0   \n",
            "1  test_2.jpg             0            1           0               0   \n",
            "2  test_3.jpg             0            1           0               0   \n",
            "\n",
            "   LABEL_WHITE  LABEL_MISPLACED  LABEL_NONE  BOTTLE_NONE  \n",
            "0            0                0           0            0  \n",
            "1            0                1           0            0  \n",
            "2            0                0           0            0  \n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# FUNÇÕES DE TESTE E SUBMISSÃO\n",
        "# =============================================================================\n",
        "\n",
        "def ensemble_predict(models, X):\n",
        "    \"\"\"Faz previsão média de um conjunto de modelos\"\"\"\n",
        "    if isinstance(models, dict):\n",
        "        models = list(models.values())\n",
        "    \n",
        "    preds = np.zeros((X.shape[0], NUM_CLASSES))\n",
        "    for model in models:\n",
        "        preds += model.predict(X, verbose=0)\n",
        "    return preds / len(models)\n",
        "\n",
        "def generate_submission(model, test_dir, output_path='submission.csv'):\n",
        "    \"\"\"\n",
        "    Gera arquivo de submissão no formato correto para competição\n",
        "    \n",
        "    Args:\n",
        "        model: Modelo(s) para fazer previsões\n",
        "        test_dir: Diretório com imagens de teste\n",
        "        output_path: Caminho completo para salvar o CSV (incluindo diretório e nome do arquivo)\n",
        "    \"\"\"\n",
        "    # 1. Carregar metadados de teste\n",
        "    test_csv_path = os.path.join(DATA_DIR, 'test.csv')\n",
        "    if not os.path.exists(test_csv_path):\n",
        "        raise FileNotFoundError(f\"Arquivo test.csv não encontrado em: {test_csv_path}\")\n",
        "    \n",
        "    test_df = pd.read_csv(test_csv_path)\n",
        "    \n",
        "    # 2. Carregar e pré-processar imagens de teste\n",
        "    X_test = []\n",
        "    valid_ids = []\n",
        "    missing_count = 0\n",
        "    \n",
        "    for img_id in test_df['id']:\n",
        "        found = False\n",
        "        # Tentar diferentes extensões\n",
        "        for ext in ['', '.jpg', '.jpeg', '.png']:\n",
        "            img_path = os.path.join(test_dir, img_id + ext)\n",
        "            if os.path.exists(img_path):\n",
        "                try:\n",
        "                    img = load_and_preprocess_image(img_path)\n",
        "                    X_test.append(img.numpy())\n",
        "                    valid_ids.append(img_id)\n",
        "                    found = True\n",
        "                    break\n",
        "                except Exception as e:\n",
        "                    print(f\"[ERRO] Falha ao carregar {img_path}: {str(e)}\")\n",
        "                    dummy_img = np.zeros((*IMG_SIZE, 3), dtype=np.float32)\n",
        "                    X_test.append(dummy_img)\n",
        "                    valid_ids.append(img_id)\n",
        "                    found = True\n",
        "                    break\n",
        "        \n",
        "        if not found:\n",
        "            print(f\"[AVISO] Imagem {img_id} não encontrada. Preenchendo com zeros.\")\n",
        "            dummy_img = np.zeros((*IMG_SIZE, 3), dtype=np.float32)\n",
        "            X_test.append(dummy_img)\n",
        "            valid_ids.append(img_id)\n",
        "            missing_count += 1\n",
        "    \n",
        "    X_test = np.array(X_test)\n",
        "    \n",
        "    # 3. Fazer previsões\n",
        "    if isinstance(model, (list, dict)):\n",
        "        y_pred = ensemble_predict(model, X_test)\n",
        "    else:\n",
        "        test_ds = tf.data.Dataset.from_tensor_slices(X_test)\n",
        "        test_ds = test_ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "        y_pred = model.predict(test_ds, verbose=1)\n",
        "    \n",
        "    # 4. Binarizar as previsões (threshold=0.5)\n",
        "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "    \n",
        "    # 5. Criar DataFrame de submissão COM A MESMA ORDEM DO SAMPLE\n",
        "    # Manter a ordem original das colunas do test.csv/sample_submission.csv\n",
        "    submission_df = pd.DataFrame(columns=test_df.columns)\n",
        "    submission_df['id'] = valid_ids\n",
        "    \n",
        "    # Preencher as colunas de defeitos na ordem correta\n",
        "    for i, defect in enumerate(DEFECTS):\n",
        "        submission_df[defect] = y_pred_binary[:, i]\n",
        "    \n",
        "    # 6. Salvar arquivo no caminho especificado\n",
        "    submission_df.to_csv(output_path, index=False)\n",
        "    print(f\"[SUCESSO] Arquivo de submissão gerado: {output_path}\")\n",
        "    print(f\"         Total de imagens processadas: {len(submission_df)}\")\n",
        "    print(f\"         Imagens faltantes: {missing_count}\")\n",
        "    \n",
        "    return submission_df\n",
        "\n",
        "# =============================================================================\n",
        "# CARREGAR MODELOS SALVOS\n",
        "# =============================================================================\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Carregar modelos do ensemble\n",
        "trained_models = {\n",
        "    'efficientnet': load_model('ensemble_models/efficientnet_model.keras'),\n",
        "    'resnet50': load_model('ensemble_models/resnet50_model.keras'),\n",
        "    'inceptionv3': load_model('ensemble_models/inceptionv3_model.keras')\n",
        "}\n",
        "\n",
        "# O melhor modelo é o ensemble\n",
        "best_model = trained_models\n",
        "\n",
        "# =============================================================================\n",
        "# GERAR SUBMISSÃO FINAL\n",
        "# =============================================================================\n",
        "\n",
        "# Diretório de teste\n",
        "test_dir = os.path.join(DATA_DIR, 'test')\n",
        "\n",
        "# Salvando arquivo de submissão\n",
        "save_path = r'C:\\Users\\fabia\\Downloads\\sample_submission.csv' \n",
        "\n",
        "if os.path.exists(test_dir):\n",
        "    print(\"\\n[INFO] Gerando submissão com o melhor modelo (ensemble)...\")\n",
        "    submission = generate_submission(\n",
        "        best_model, \n",
        "        test_dir, \n",
        "        output_path=save_path  # Usando o caminho personalizado\n",
        "    )\n",
        "    \n",
        "    print(\"\\n[INFO] Submissão gerada com sucesso!\")\n",
        "    print(f\"  - Arquivo: {save_path}\")\n",
        "    print(f\"  - Modelo usado: Ensemble completo\")\n",
        "    \n",
        "    # Verificação rápida do formato\n",
        "    print(\"\\n[VERIFICAÇÃO] Primeiras linhas do arquivo gerado:\")\n",
        "    print(submission.head(3))\n",
        "else:\n",
        "    print(\"\\n[AVISO] Diretório de teste não encontrado. Pulando geração de submissão.\")\n",
        "    print(f\"  Caminho verificado: {test_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XXX9ZrSe_8Z"
      },
      "source": [
        "## Regressão Linear vs Logística\n",
        "\n",
        "### Regressão Linear\n",
        "A regressão linear estima um valor contínuo.\n",
        "Porém, para classificação binária, ela é inadequada, pois não restringe a saída entre 0 e 1.\n",
        "\n",
        "### Regressão Logística\n",
        "Usa a **função sigmoide** para restringir a saída. Por isso, usamos **regressão logística** (ou generalizações com redes neurais) para problemas como este.\n",
        "\n",
        "### No caso do Controle de Qualidade de Fabricação:\n",
        "Cada classe é binária (0 ou 1) → modelo de classificação multi-label → usamos redes neurais com 8 saídas sigmoides (uma para cada defeito).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLtOkf7Ri498"
      },
      "source": [
        "## 📊 Viés e Variância\n",
        "\n",
        "- **Viés alto**: modelo muito simples, não aprende bem → erro alto em treino e teste.\n",
        "- **Variância alta**: modelo muito complexo, memoriza os dados → erro baixo em treino, alto em teste.\n",
        "\n",
        "O gráfico acima mostra se há overfitting (val_loss subindo).\n",
        "\n",
        "Podemos mitigar com:\n",
        "- Mais dados\n",
        "- Regularização\n",
        "- Dropout\n",
        "- Reduzir complexidade da rede\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbK-l_tpjJtU"
      },
      "source": [
        "## ❗ Vanishing Gradient e Análise dos Pesos\n",
        "\n",
        "**Vanishing gradient** ocorre quando usamos funções como tanh ou sigmoid em muitas camadas profundas, fazendo o gradiente \"sumir\" e os pesos pararem de ser atualizados.\n",
        "\n",
        "Para evitar:\n",
        "- Usar ReLU\n",
        "- Inicialização adequada dos pesos\n",
        "- Normalização\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
